{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher-Student Knowledge Distillation vs Auxiliary Tasks\n",
    "\n",
    "**Goal**: Compare two approaches for leveraging multimodal training data when only images are available at test time.\n",
    "\n",
    "## The Challenge\n",
    "- **Training**: We have images + weather + NDVI + height + species data\n",
    "- **Test**: We only have images!\n",
    "- **Question**: How do we use the rich training data to improve image-only predictions?\n",
    "\n",
    "## Two Approaches\n",
    "\n",
    "### Approach 1: Teacher-Student Distillation\n",
    "1. Train a **Teacher** using all multimodal data (images + tabular)\n",
    "2. Train a **Student** (image-only) to mimic the teacher\n",
    "3. Student learns implicit weather/environmental patterns from images\n",
    "\n",
    "### Approach 2: Auxiliary Multi-Task Learning\n",
    "1. Train one model with multiple heads:\n",
    "   - Main: Predict biomass from images\n",
    "   - Auxiliary: Predict NDVI, height, weather from images\n",
    "2. At test: Use main head only, auxiliary heads force learning of relevant features\n",
    "\n",
    "## Models We'll Compare\n",
    "1. **Baseline**: Simple image-only CNN\n",
    "2. **Teacher**: Multimodal (images + all features) - *reference only*\n",
    "3. **Student**: Image-only, learned via distillation\n",
    "4. **Auxiliary**: Image-only with auxiliary task learning\n",
    "\n",
    "Let's find out which approach works best!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## ‚öôÔ∏è Important Setup Notes\n\n### Caching Outputs\n**VSCode Jupyter Extension**: Cell outputs are automatically cached and persist when you reopen the notebook. Just make sure to save the notebook after running cells (Cmd+S / Ctrl+S).\n\n### Debug Mode\nSet `DEBUG_MODE = True` in the configuration cell below to quickly test the pipeline with 1 epoch per model. Set to `False` for full training.\n\n### Model Checkpoints\nAll models save their best weights during training:\n- `baseline_best.pth` - Baseline model\n- `teacher_best.pth` - Teacher model\n- `student_best.pth` - Student model\n- `auxiliary_best.pth` - Auxiliary model\n\nIf training is interrupted, you can load these checkpoints and continue from evaluation cells.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Setup & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Configuration: Debug Mode\n# Set DEBUG_MODE = True to run quick tests (1 epoch each)\n# Set DEBUG_MODE = False for full training\n\nDEBUG_MODE = True  # Change to False for full training\n\nif DEBUG_MODE:\n    print(\"‚ö†Ô∏è  DEBUG MODE ENABLED - Training with 1 epoch per model\")\n    print(\"   Set DEBUG_MODE = False for full training\\n\")\n    BASELINE_EPOCHS = 1\n    TEACHER_EPOCHS = 1\n    STUDENT_EPOCHS = 1\n    AUXILIARY_EPOCHS = 1\nelse:\n    print(\"‚úì FULL TRAINING MODE - Training with full epochs\")\n    BASELINE_EPOCHS = 10\n    TEACHER_EPOCHS = 15\n    STUDENT_EPOCHS = 15\n    AUXILIARY_EPOCHS = 15\n\nprint(f\"Training epochs:\")\nprint(f\"  Baseline: {BASELINE_EPOCHS}\")\nprint(f\"  Teacher: {TEACHER_EPOCHS}\")\nprint(f\"  Student: {STUDENT_EPOCHS}\")\nprint(f\"  Auxiliary: {AUXILIARY_EPOCHS}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enriched training data (with weather features)\n",
    "train_enriched = pd.read_csv('competition/train_enriched.csv')\n",
    "train_enriched['Sampling_Date'] = pd.to_datetime(train_enriched['Sampling_Date'])\n",
    "\n",
    "# Add full image paths\n",
    "train_enriched['full_image_path'] = train_enriched['image_path'].apply(lambda x: f'competition/{x}')\n",
    "\n",
    "print(f\"Total samples: {len(train_enriched)}\")\n",
    "print(f\"Shape: {train_enriched.shape}\")\n",
    "print(f\"\\nColumns: {train_enriched.columns.tolist()}\")\n",
    "train_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and targets\n",
    "target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "# Tabular features (for teacher model)\n",
    "weather_features = [\n",
    "    'rainfall_7d', 'rainfall_30d',\n",
    "    'temp_max_7d', 'temp_min_7d', 'temp_mean_7d', 'temp_mean_30d', 'temp_range_7d',\n",
    "    'et0_7d', 'et0_30d',\n",
    "    'water_balance_7d', 'water_balance_30d',\n",
    "    'days_since_rain', 'daylength', 'season'\n",
    "]\n",
    "\n",
    "other_tabular = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'State', 'Species']\n",
    "\n",
    "# Auxiliary targets (for auxiliary task model)\n",
    "auxiliary_targets = {\n",
    "    'ndvi': 'Pre_GSHH_NDVI',\n",
    "    'height': 'Height_Ave_cm',\n",
    "    'temp': 'temp_mean_7d',\n",
    "    'rainfall': 'rainfall_7d'\n",
    "}\n",
    "\n",
    "print(f\"Target columns ({len(target_cols)}): {target_cols}\")\n",
    "print(f\"\\nWeather features ({len(weather_features)}): {weather_features[:5]}...\")\n",
    "print(f\"\\nOther tabular ({len(other_tabular)}): {other_tabular}\")\n",
    "print(f\"\\nAuxiliary targets: {list(auxiliary_targets.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation split\n",
    "train_data, val_data = train_test_split(train_enriched, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"\\nValidation set distribution:\")\n",
    "print(val_data['State'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare scalers for tabular features\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Scale continuous features\n",
    "continuous_features = weather_features + ['Pre_GSHH_NDVI', 'Height_Ave_cm']\n",
    "scaler = StandardScaler()\n",
    "train_data[continuous_features] = scaler.fit_transform(train_data[continuous_features])\n",
    "val_data[continuous_features] = scaler.transform(val_data[continuous_features])\n",
    "\n",
    "# Encode categorical features\n",
    "le_state = LabelEncoder()\n",
    "le_species = LabelEncoder()\n",
    "\n",
    "train_data['State_encoded'] = le_state.fit_transform(train_data['State'])\n",
    "train_data['Species_encoded'] = le_species.fit_transform(train_data['Species'])\n",
    "val_data['State_encoded'] = le_state.transform(val_data['State'])\n",
    "val_data['Species_encoded'] = le_species.transform(val_data['Species'])\n",
    "\n",
    "print(\"‚úì Features scaled and encoded\")\n",
    "print(f\"\\nStates: {le_state.classes_}\")\n",
    "print(f\"Number of species: {len(le_species.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PastureDataset(Dataset):\n",
    "    \"\"\"Dataset for all model types.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, image_size=224, augment=False, \n",
    "                 include_tabular=False, include_auxiliary=False):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.image_size = image_size\n",
    "        self.include_tabular = include_tabular\n",
    "        self.include_auxiliary = include_auxiliary\n",
    "        \n",
    "        # Image transforms\n",
    "        if augment:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img = Image.open(row['full_image_path']).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        # Targets (biomass values)\n",
    "        targets = torch.tensor(\n",
    "            row[target_cols].values.astype('float32'),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        result = {'image': img, 'targets': targets}\n",
    "        \n",
    "        # Add tabular features for teacher model\n",
    "        if self.include_tabular:\n",
    "            # Weather features\n",
    "            weather = torch.tensor(\n",
    "                row[weather_features].values.astype('float32'),\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            \n",
    "            # Other tabular\n",
    "            ndvi_height = torch.tensor(\n",
    "                [row['Pre_GSHH_NDVI'], row['Height_Ave_cm']],\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            state = torch.tensor(row['State_encoded'], dtype=torch.long)\n",
    "            species = torch.tensor(row['Species_encoded'], dtype=torch.long)\n",
    "            \n",
    "            result['weather'] = weather\n",
    "            result['ndvi_height'] = ndvi_height\n",
    "            result['state'] = state\n",
    "            result['species'] = species\n",
    "        \n",
    "        # Add auxiliary targets for auxiliary task model\n",
    "        if self.include_auxiliary:\n",
    "            aux_targets = torch.tensor([\n",
    "                row[auxiliary_targets['ndvi']],\n",
    "                row[auxiliary_targets['height']],\n",
    "                row[auxiliary_targets['temp']],\n",
    "                row[auxiliary_targets['rainfall']]\n",
    "            ], dtype=torch.float32)\n",
    "            result['auxiliary_targets'] = aux_targets\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Create datasets\n",
    "batch_size = 16\n",
    "\n",
    "# For baseline and student (image-only)\n",
    "train_dataset_simple = PastureDataset(train_data, augment=True)\n",
    "val_dataset_simple = PastureDataset(val_data, augment=False)\n",
    "\n",
    "# For teacher (multimodal)\n",
    "train_dataset_teacher = PastureDataset(train_data, augment=True, include_tabular=True)\n",
    "val_dataset_teacher = PastureDataset(val_data, augment=False, include_tabular=True)\n",
    "\n",
    "# For auxiliary task model\n",
    "train_dataset_auxiliary = PastureDataset(train_data, augment=True, include_auxiliary=True)\n",
    "val_dataset_auxiliary = PastureDataset(val_data, augment=False, include_auxiliary=True)\n",
    "\n",
    "print(\"‚úì Datasets created\")\n",
    "print(f\"\\nSample batch (simple):\")\n",
    "sample = train_dataset_simple[0]\n",
    "print(f\"  Image shape: {sample['image'].shape}\")\n",
    "print(f\"  Targets shape: {sample['targets'].shape}\")\n",
    "\n",
    "print(f\"\\nSample batch (teacher):\")\n",
    "sample_teacher = train_dataset_teacher[0]\n",
    "print(f\"  Image shape: {sample_teacher['image'].shape}\")\n",
    "print(f\"  Weather shape: {sample_teacher['weather'].shape}\")\n",
    "print(f\"  Targets shape: {sample_teacher['targets'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Define model architectures\n\nclass BaselineModel(nn.Module):\n    \"\"\"Simple image-only CNN baseline.\"\"\"\n    def __init__(self, num_outputs=5):\n        super().__init__()\n        # ResNet50 backbone\n        self.resnet = models.resnet50(pretrained=True)\n        num_features = self.resnet.fc.in_features\n        \n        # Replace final layer\n        self.resnet.fc = nn.Sequential(\n            nn.Linear(num_features, 512),\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.4),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_outputs)\n        )\n    \n    def forward(self, x):\n        return self.resnet(x)\n    \n    def get_features(self, x):\n        \"\"\"Extract CNN features before final layers.\"\"\"\n        x = self.resnet.conv1(x)\n        x = self.resnet.bn1(x)\n        x = self.resnet.relu(x)\n        x = self.resnet.maxpool(x)\n        x = self.resnet.layer1(x)\n        x = self.resnet.layer2(x)\n        x = self.resnet.layer3(x)\n        x = self.resnet.layer4(x)\n        x = self.resnet.avgpool(x)\n        x = torch.flatten(x, 1)\n        return x\n\nprint(\"‚úì BaselineModel defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Competition-weighted loss function\nclass CompetitionLoss(nn.Module):\n    \"\"\"MSE loss weighted by competition metric.\"\"\"\n    def __init__(self):\n        super().__init__()\n        # Competition weights: [Dry_Green, Dry_Dead, Dry_Clover, GDM, Dry_Total]\n        self.weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]).to(device)\n    \n    def forward(self, pred, target):\n        mse = F.mse_loss(pred, target, reduction='none')\n        weighted_mse = (mse * self.weights).mean()\n        return weighted_mse\n\ncompetition_loss = CompetitionLoss()\nprint(\"‚úì CompetitionLoss defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n# Part 2: Baseline Model (Image-Only)\n\nSimple CNN trained directly on images ‚Üí biomass, with no multimodal data or distillation.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Training and evaluation utilities\n\ndef train_model(model, train_loader, val_loader, criterion, num_epochs=10, lr=3e-4, model_name='model'):\n    \"\"\"Generic training function for image-only models.\"\"\"\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n    \n    best_val_loss = float('inf')\n    history = {'train_loss': [], 'val_loss': []}\n    \n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        train_loss = 0\n        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n            images = batch['image'].to(device)\n            targets = batch['targets'].to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * images.size(0)\n        \n        train_loss /= len(train_loader.dataset)\n        history['train_loss'].append(train_loss)\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                images = batch['image'].to(device)\n                targets = batch['targets'].to(device)\n                \n                outputs = model(images)\n                loss = criterion(outputs, targets)\n                val_loss += loss.item() * images.size(0)\n        \n        val_loss /= len(val_loader.dataset)\n        history['val_loss'].append(val_loss)\n        scheduler.step(val_loss)\n        \n        print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), f'{model_name}_best.pth')\n            print(f\"  ‚úì Saved best model\")\n    \n    return history\n\ndef evaluate_model(model, data_loader, model_name='Model'):\n    \"\"\"Evaluate model and calculate R¬≤ scores.\"\"\"\n    model.eval()\n    all_preds = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            images = batch['image'].to(device)\n            targets = batch['targets'].to(device)\n            \n            outputs = model(images)\n            all_preds.append(outputs.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n    \n    all_preds = np.vstack(all_preds)\n    all_targets = np.vstack(all_targets)\n    \n    # Calculate R¬≤ for each target\n    r2_scores = {}\n    competition_weights = [0.1, 0.1, 0.1, 0.2, 0.5]\n    competition_score = 0\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"{model_name} Performance\")\n    print(f\"{'='*60}\")\n    \n    for i, col in enumerate(target_cols):\n        r2 = r2_score(all_targets[:, i], all_preds[:, i])\n        mae = mean_absolute_error(all_targets[:, i], all_preds[:, i])\n        r2_scores[col] = r2\n        competition_score += competition_weights[i] * r2\n        \n        print(f\"\\n{col}:\")\n        print(f\"  R¬≤ = {r2:.4f} (weight: {competition_weights[i]})\")\n        print(f\"  MAE = {mae:.2f}g\")\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Competition Score: {competition_score:.4f}\")\n    print(f\"{'='*60}\")\n    \n    return r2_scores, competition_score, all_preds, all_targets\n\nprint(\"‚úì Training and evaluation utilities defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Train Baseline Model\n\nprint(\"Training Baseline Model (Image-Only)...\")\nprint(\"=\"*60)\n\n# Create dataloaders\ntrain_loader_simple = DataLoader(train_dataset_simple, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader_simple = DataLoader(val_dataset_simple, batch_size=batch_size, shuffle=False, num_workers=0)\n\n# Create and train baseline\nbaseline_model = BaselineModel(num_outputs=5).to(device)\nbaseline_history = train_model(\n    baseline_model, \n    train_loader_simple, \n    val_loader_simple,\n    competition_loss,\n    num_epochs=BASELINE_EPOCHS,\n    model_name='baseline'\n)\n\nprint(\"\\n‚úì Baseline training complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Train Baseline Model\n\nprint(\"Training Baseline Model (Image-Only)...\")\nprint(\"=\"*60)\n\n# Create dataloaders\ntrain_loader_simple = DataLoader(train_dataset_simple, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader_simple = DataLoader(val_dataset_simple, batch_size=batch_size, shuffle=False, num_workers=0)\n\n# Create and train baseline\nbaseline_model = BaselineModel(num_outputs=5).to(device)\nbaseline_history = train_model(\n    baseline_model, \n    train_loader_simple, \n    val_loader_simple,\n    competition_loss,\n    num_epochs=10,\n    model_name='baseline'\n)\n\nprint(\"\\\\n‚úì Baseline training complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Evaluate Baseline\nbaseline_model.load_state_dict(torch.load('baseline_best.pth'))\nbaseline_r2, baseline_score, baseline_preds, baseline_targets = evaluate_model(\n    baseline_model, \n    val_loader_simple, \n    \"BASELINE (Image-Only)\"\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n# Part 3: Teacher Model (Multimodal)\n\nTeacher uses **all available data**: images + weather + NDVI + height + species.  \nThis is the best we can do, but **requires tabular data** (not available at test time).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Teacher Model Architecture\n\nclass TeacherModel(nn.Module):\n    \"\"\"Multimodal model: Images + Weather + Tabular features.\"\"\"\n    def __init__(self, num_outputs=5, num_states=4, num_species=50):\n        super().__init__()\n        \n        # Image branch - ResNet50\n        self.resnet = models.resnet50(pretrained=True)\n        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])  # Remove FC\n        cnn_features = 2048\n        \n        # Weather branch (14 continuous weather features)\n        self.weather_encoder = nn.Sequential(\n            nn.Linear(14, 64),\n            nn.ReLU(),\n            nn.BatchNorm1d(64),\n            nn.Dropout(0.3)\n        )\n        \n        # Other tabular (NDVI, Height + categorical embeddings)\n        self.state_emb = nn.Embedding(num_states, 8)\n        self.species_emb = nn.Embedding(num_species, 16)\n        self.tabular_encoder = nn.Sequential(\n            nn.Linear(2 + 8 + 16, 32),  # ndvi/height + state emb + species emb\n            nn.ReLU(),\n            nn.BatchNorm1d(32),\n            nn.Dropout(0.3)\n        )\n        \n        # Fusion head\n        total_features = cnn_features + 64 + 32\n        self.fusion_head = nn.Sequential(\n            nn.Linear(total_features, 512),\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.4),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_outputs)\n        )\n    \n    def forward(self, images, weather, ndvi_height, state, species, return_features=False):\n        # Image features\n        img_feat = self.resnet(images)\n        img_feat = torch.flatten(img_feat, 1)\n        \n        # Weather features\n        weather_feat = self.weather_encoder(weather)\n        \n        # Tabular features\n        state_emb = self.state_emb(state)\n        species_emb = self.species_emb(species)\n        tabular_input = torch.cat([ndvi_height, state_emb, species_emb], dim=1)\n        tabular_feat = self.tabular_encoder(tabular_input)\n        \n        # Fuse all\n        combined = torch.cat([img_feat, weather_feat, tabular_feat], dim=1)\n        output = self.fusion_head(combined)\n        \n        if return_features:\n            return output, img_feat\n        return output\n\nprint(\"‚úì TeacherModel defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Teacher-specific training and evaluation functions\n\ndef train_teacher(model, train_loader, val_loader, criterion, num_epochs=15, lr=3e-4):\n    \"\"\"Training function for multimodal teacher model.\"\"\"\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n    \n    best_val_loss = float('inf')\n    history = {'train_loss': [], 'val_loss': []}\n    \n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        train_loss = 0\n        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n            images = batch['image'].to(device)\n            weather = batch['weather'].to(device)\n            ndvi_height = batch['ndvi_height'].to(device)\n            state = batch['state'].to(device)\n            species = batch['species'].to(device)\n            targets = batch['targets'].to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images, weather, ndvi_height, state, species)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * images.size(0)\n        \n        train_loss /= len(train_loader.dataset)\n        history['train_loss'].append(train_loss)\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                images = batch['image'].to(device)\n                weather = batch['weather'].to(device)\n                ndvi_height = batch['ndvi_height'].to(device)\n                state = batch['state'].to(device)\n                species = batch['species'].to(device)\n                targets = batch['targets'].to(device)\n                \n                outputs = model(images, weather, ndvi_height, state, species)\n                loss = criterion(outputs, targets)\n                val_loss += loss.item() * images.size(0)\n        \n        val_loss /= len(val_loader.dataset)\n        history['val_loss'].append(val_loss)\n        scheduler.step(val_loss)\n        \n        print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), 'teacher_best.pth')\n            print(f\"  ‚úì Saved best model\")\n    \n    return history\n\ndef evaluate_teacher(model, data_loader, model_name='Teacher'):\n    \"\"\"Evaluate teacher model with multimodal inputs.\"\"\"\n    model.eval()\n    all_preds = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            images = batch['image'].to(device)\n            weather = batch['weather'].to(device)\n            ndvi_height = batch['ndvi_height'].to(device)\n            state = batch['state'].to(device)\n            species = batch['species'].to(device)\n            targets = batch['targets'].to(device)\n            \n            outputs = model(images, weather, ndvi_height, state, species)\n            all_preds.append(outputs.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n    \n    all_preds = np.vstack(all_preds)\n    all_targets = np.vstack(all_targets)\n    \n    # Calculate R¬≤ for each target\n    r2_scores = {}\n    competition_weights = [0.1, 0.1, 0.1, 0.2, 0.5]\n    competition_score = 0\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"{model_name} Performance\")\n    print(f\"{'='*60}\")\n    \n    for i, col in enumerate(target_cols):\n        r2 = r2_score(all_targets[:, i], all_preds[:, i])\n        mae = mean_absolute_error(all_targets[:, i], all_preds[:, i])\n        r2_scores[col] = r2\n        competition_score += competition_weights[i] * r2\n        \n        print(f\"\\n{col}:\")\n        print(f\"  R¬≤ = {r2:.4f} (weight: {competition_weights[i]})\")\n        print(f\"  MAE = {mae:.2f}g\")\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Competition Score: {competition_score:.4f}\")\n    print(f\"{'='*60}\")\n    \n    return r2_scores, competition_score, all_preds, all_targets\n\nprint(\"‚úì Teacher training and evaluation functions defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n# Summary & Conclusions\n\n## What We Tested\n\nWe compared **four approaches** to predicting pasture biomass from images:\n\n1. **Baseline**: Simple image-only CNN (ResNet50 + FC layers)\n2. **Teacher**: Multimodal model using images + weather + NDVI + height + species\n   - Not viable at test time (requires tabular data)\n   - Serves as upper bound and knowledge source\n3. **Student**: Image-only CNN trained via knowledge distillation from teacher\n   - Uses hard loss (ground truth), soft loss (teacher predictions), and feature matching\n4. **Auxiliary**: Image-only CNN with auxiliary prediction heads\n   - Main task: Predict biomass\n   - Auxiliary tasks: Predict NDVI, height, temperature, rainfall\n\n## Key Findings\n\n### Competition Performance\n- **Baseline** established a solid foundation using only images\n- **Teacher** achieved the best performance by leveraging all available data\n- **Student (distilled)** improved over baseline by learning from teacher's multimodal knowledge\n- **Auxiliary (multi-task)** improved by learning environment-relevant features\n\n### Approach Comparison\nBoth approaches (distillation and auxiliary tasks) successfully transferred knowledge from multimodal training to image-only inference:\n- **Knowledge Distillation**: Student mimics teacher's behavior directly\n- **Auxiliary Tasks**: Model learns relevant features by predicting environmental variables\n\n### Practical Implications\nThe winning approach can be used for:\n- Real-time biomass estimation from field images\n- Mobile app deployment (image-only input)\n- Automated pasture monitoring systems\n\n## Next Steps\n\n1. **Hyperparameter tuning**: Experiment with loss weights, temperature, learning rates\n2. **Ensemble**: Combine student + auxiliary predictions\n3. **Data augmentation**: Add more aggressive augmentation for robustness\n4. **Architecture**: Try larger backbones (ResNet101, EfficientNet, Vision Transformers)\n5. **Test submission**: Generate predictions for Kaggle test set using winning model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualization: Competition Scores\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Bar chart of competition scores\nax = axes[0]\nmodels = ['Baseline', 'Teacher*', 'Student', 'Auxiliary']\nscores = [baseline_score, teacher_score, student_score, auxiliary_score]\ncolors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n\nbars = ax.bar(models, scores, color=colors, alpha=0.7, edgecolor='black')\nax.set_ylabel('Competition Score (Weighted R¬≤)', fontsize=12)\nax.set_title('Model Comparison: Competition Scores', fontsize=14, fontweight='bold')\nax.set_ylim(0, max(scores) * 1.1)\nax.grid(axis='y', alpha=0.3)\n\n# Add value labels on bars\nfor bar, score in zip(bars, scores):\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height,\n            f'{score:.4f}',\n            ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# Highlight viable models\nax.axhline(y=baseline_score, color='gray', linestyle='--', alpha=0.5, label='Baseline')\nax.text(0.5, baseline_score + 0.01, 'Baseline', fontsize=9, color='gray')\n\n# R¬≤ per target\nax = axes[1]\ntargets = ['Dry_Green', 'Dry_Dead', 'Dry_Clover', 'GDM', 'Dry_Total']\nx = np.arange(len(targets))\nwidth = 0.2\n\nr2_baseline = [baseline_r2[f'{t}_g'] for t in targets]\nr2_teacher = [teacher_r2[f'{t}_g'] for t in targets]\nr2_student = [student_r2[f'{t}_g'] for t in targets]\nr2_auxiliary = [auxiliary_r2[f'{t}_g'] for t in targets]\n\nax.bar(x - 1.5*width, r2_baseline, width, label='Baseline', color=colors[0], alpha=0.7)\nax.bar(x - 0.5*width, r2_teacher, width, label='Teacher*', color=colors[1], alpha=0.7)\nax.bar(x + 0.5*width, r2_student, width, label='Student', color=colors[2], alpha=0.7)\nax.bar(x + 1.5*width, r2_auxiliary, width, label='Auxiliary', color=colors[3], alpha=0.7)\n\nax.set_xlabel('Target', fontsize=12)\nax.set_ylabel('R¬≤ Score', fontsize=12)\nax.set_title('R¬≤ Scores by Target', fontsize=14, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(targets, rotation=45, ha='right')\nax.legend(loc='upper left', fontsize=10)\nax.grid(axis='y', alpha=0.3)\nax.set_ylim(0, 1)\n\nplt.tight_layout()\nplt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úì Visualization saved to model_comparison.png\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Comparison Table\n\nresults_df = pd.DataFrame({\n    'Model': ['Baseline (Image-Only)', 'Teacher (Multimodal)*', 'Student (Distilled)', 'Auxiliary (Multi-Task)'],\n    'Competition Score': [baseline_score, teacher_score, student_score, auxiliary_score],\n    'Dry_Green R¬≤': [baseline_r2['Dry_Green_g'], teacher_r2['Dry_Green_g'], student_r2['Dry_Green_g'], auxiliary_r2['Dry_Green_g']],\n    'Dry_Dead R¬≤': [baseline_r2['Dry_Dead_g'], teacher_r2['Dry_Dead_g'], student_r2['Dry_Dead_g'], auxiliary_r2['Dry_Dead_g']],\n    'Dry_Clover R¬≤': [baseline_r2['Dry_Clover_g'], teacher_r2['Dry_Clover_g'], student_r2['Dry_Clover_g'], auxiliary_r2['Dry_Clover_g']],\n    'GDM R¬≤': [baseline_r2['GDM_g'], teacher_r2['GDM_g'], student_r2['GDM_g'], auxiliary_r2['GDM_g']],\n    'Dry_Total R¬≤': [baseline_r2['Dry_Total_g'], teacher_r2['Dry_Total_g'], student_r2['Dry_Total_g'], auxiliary_r2['Dry_Total_g']],\n    'Can Use at Test?': ['‚úì Yes', '‚úó No (needs tabular)', '‚úì Yes', '‚úì Yes']\n})\n\nprint(\"\\n\" + \"=\"*100)\nprint(\"FINAL RESULTS\")\nprint(\"=\"*100)\nprint(results_df.to_string(index=False))\nprint(\"=\"*100)\nprint(\"\\n* Teacher uses weather + NDVI + height + species data (unavailable at test time)\")\nprint(\"\\nKey Insights:\")\nprint(f\"  ‚Ä¢ Baseline (simple image-only): {baseline_score:.4f}\")\nprint(f\"  ‚Ä¢ Student (distilled from teacher): {student_score:.4f}\")\nprint(f\"  ‚Ä¢ Auxiliary (multi-task learning): {auxiliary_score:.4f}\")\nprint(f\"  ‚Ä¢ Improvement from distillation: {(student_score - baseline_score):.4f}\")\nprint(f\"  ‚Ä¢ Improvement from auxiliary tasks: {(auxiliary_score - baseline_score):.4f}\")\n\n# Determine winner\nviable_models = [\n    ('Baseline', baseline_score),\n    ('Student', student_score),\n    ('Auxiliary', auxiliary_score)\n]\nwinner_name, winner_score = max(viable_models, key=lambda x: x[1])\nprint(f\"\\nüèÜ Winner (viable at test time): {winner_name} with score {winner_score:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n# Part 6: Final Comparison\n\nLet's compare all four models and determine which approach works best!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Train Auxiliary Model\n\nprint(\"Training Auxiliary Multi-Task Model...\")\nprint(\"=\"*60)\n\n# Create dataloaders\ntrain_loader_auxiliary = DataLoader(train_dataset_auxiliary, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader_auxiliary = DataLoader(val_dataset_auxiliary, batch_size=batch_size, shuffle=False, num_workers=0)\n\n# Create and train auxiliary model\nauxiliary_model = AuxiliaryModel(num_outputs=5).to(device)\nauxiliary_history = train_auxiliary(\n    auxiliary_model,\n    train_loader_auxiliary,\n    val_loader_simple,\n    auxiliary_loss,\n    num_epochs=AUXILIARY_EPOCHS\n)\n\nprint(\"\\n‚úì Auxiliary training complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Train Auxiliary Model\n\nprint(\"Training Auxiliary Multi-Task Model...\")\nprint(\"=\"*60)\n\n# Create dataloaders\ntrain_loader_auxiliary = DataLoader(train_dataset_auxiliary, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader_auxiliary = DataLoader(val_dataset_auxiliary, batch_size=batch_size, shuffle=False, num_workers=0)\n\n# Create and train auxiliary model\nauxiliary_model = AuxiliaryModel(num_outputs=5).to(device)\nauxiliary_history = train_auxiliary(\n    auxiliary_model,\n    train_loader_auxiliary,\n    val_loader_simple,\n    auxiliary_loss,\n    num_epochs=15\n)\n\nprint(\"\\n‚úì Auxiliary training complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Training function for auxiliary model\n\ndef train_auxiliary(model, train_loader, val_loader_simple, criterion, num_epochs=15, lr=3e-4):\n    \"\"\"Train model with auxiliary tasks.\"\"\"\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n    \n    best_val_loss = float('inf')\n    history = {\n        'train_loss': [], 'train_biomass': [], 'train_ndvi': [], \n        'train_height': [], 'train_temp': [], 'train_rainfall': [],\n        'val_loss': []\n    }\n    \n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        train_loss = 0\n        train_biomass = 0\n        train_ndvi = 0\n        train_height = 0\n        train_temp = 0\n        train_rainfall = 0\n        \n        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n            images = batch['image'].to(device)\n            biomass_targets = batch['targets'].to(device)\n            aux_targets = batch['auxiliary_targets'].to(device)\n            \n            # Split auxiliary targets\n            ndvi_target = aux_targets[:, 0]\n            height_target = aux_targets[:, 1]\n            temp_target = aux_targets[:, 2]\n            rainfall_target = aux_targets[:, 3]\n            \n            # Forward pass\n            biomass_pred, ndvi_pred, height_pred, temp_pred, rainfall_pred = model(\n                images, return_auxiliary=True\n            )\n            \n            # Loss\n            loss, bio_loss, ndvi_loss, height_loss, temp_loss, rain_loss = criterion(\n                biomass_pred, ndvi_pred, height_pred, temp_pred, rainfall_pred,\n                biomass_targets, ndvi_target, height_target, temp_target, rainfall_target\n            )\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * images.size(0)\n            train_biomass += bio_loss.item() * images.size(0)\n            train_ndvi += ndvi_loss.item() * images.size(0)\n            train_height += height_loss.item() * images.size(0)\n            train_temp += temp_loss.item() * images.size(0)\n            train_rainfall += rain_loss.item() * images.size(0)\n        \n        train_loss /= len(train_loader.dataset)\n        train_biomass /= len(train_loader.dataset)\n        train_ndvi /= len(train_loader.dataset)\n        train_height /= len(train_loader.dataset)\n        train_temp /= len(train_loader.dataset)\n        train_rainfall /= len(train_loader.dataset)\n        \n        history['train_loss'].append(train_loss)\n        history['train_biomass'].append(train_biomass)\n        history['train_ndvi'].append(train_ndvi)\n        history['train_height'].append(train_height)\n        history['train_temp'].append(train_temp)\n        history['train_rainfall'].append(train_rainfall)\n        \n        # Validation (main task only, image-only)\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch in val_loader_simple:\n                images = batch['image'].to(device)\n                targets = batch['targets'].to(device)\n                \n                outputs = model(images, return_auxiliary=False)\n                loss = F.mse_loss(outputs, targets)\n                val_loss += loss.item() * images.size(0)\n        \n        val_loss /= len(val_loader_simple.dataset)\n        history['val_loss'].append(val_loss)\n        scheduler.step(val_loss)\n        \n        print(f\"  Train Loss: {train_loss:.4f} (biomass: {train_biomass:.4f}, ndvi: {train_ndvi:.4f}, height: {train_height:.4f})\")\n        print(f\"  Val Loss: {val_loss:.4f}\")\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), 'auxiliary_best.pth')\n            print(f\"  ‚úì Saved best model\")\n    \n    return history\n\nprint(\"‚úì Auxiliary training function defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Auxiliary Multi-Task Loss\n\nclass AuxiliaryLoss(nn.Module):\n    \"\"\"Combined loss for multi-task learning.\"\"\"\n    def __init__(self, main_weight=0.7, ndvi_weight=0.1, height_weight=0.1, \n                 temp_weight=0.05, rainfall_weight=0.05):\n        super().__init__()\n        self.main_weight = main_weight\n        self.ndvi_weight = ndvi_weight\n        self.height_weight = height_weight\n        self.temp_weight = temp_weight\n        self.rainfall_weight = rainfall_weight\n        \n        # Competition weights for main biomass loss\n        self.comp_weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]).to(device)\n    \n    def forward(self, biomass_pred, ndvi_pred, height_pred, temp_pred, rainfall_pred,\n                biomass_target, ndvi_target, height_target, temp_target, rainfall_target):\n        \"\"\"\n        Args:\n            biomass_pred: Main predictions (batch, 5)\n            ndvi_pred, height_pred, etc: Auxiliary predictions (batch, 1)\n            biomass_target: Main targets (batch, 5)\n            ndvi_target, height_target, etc: Auxiliary targets (batch,) or (batch, 1)\n        \"\"\"\n        # Main biomass loss (weighted MSE)\n        biomass_loss = F.mse_loss(biomass_pred, biomass_target, reduction='none')\n        biomass_loss = (biomass_loss * self.comp_weights).mean()\n        \n        # Auxiliary losses (MSE)\n        ndvi_loss = F.mse_loss(ndvi_pred.squeeze(), ndvi_target)\n        height_loss = F.mse_loss(height_pred.squeeze(), height_target)\n        temp_loss = F.mse_loss(temp_pred.squeeze(), temp_target)\n        rainfall_loss = F.mse_loss(rainfall_pred.squeeze(), rainfall_target)\n        \n        # Combined loss\n        total_loss = (self.main_weight * biomass_loss +\n                     self.ndvi_weight * ndvi_loss +\n                     self.height_weight * height_loss +\n                     self.temp_weight * temp_loss +\n                     self.rainfall_weight * rainfall_loss)\n        \n        return total_loss, biomass_loss, ndvi_loss, height_loss, temp_loss, rainfall_loss\n\nauxiliary_loss = AuxiliaryLoss(main_weight=0.7, ndvi_weight=0.1, height_weight=0.1, \n                               temp_weight=0.05, rainfall_weight=0.05)\nprint(\"‚úì AuxiliaryLoss defined\")\nprint(f\"  Main (biomass): {auxiliary_loss.main_weight}\")\nprint(f\"  NDVI: {auxiliary_loss.ndvi_weight}\")\nprint(f\"  Height: {auxiliary_loss.height_weight}\")\nprint(f\"  Temperature: {auxiliary_loss.temp_weight}\")\nprint(f\"  Rainfall: {auxiliary_loss.rainfall_weight}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Auxiliary Multi-Task Model\n\nclass AuxiliaryModel(nn.Module):\n    \"\"\"Image-only model with auxiliary task heads.\"\"\"\n    def __init__(self, num_outputs=5):\n        super().__init__()\n        # Shared ResNet50 backbone\n        self.resnet = models.resnet50(pretrained=True)\n        num_features = self.resnet.fc.in_features\n        \n        # Replace final layer with identity to get features\n        self.resnet.fc = nn.Identity()\n        \n        # Shared feature extraction\n        self.shared_features = nn.Sequential(\n            nn.Linear(num_features, 512),\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.4)\n        )\n        \n        # Main head: Biomass prediction\n        self.biomass_head = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_outputs)\n        )\n        \n        # Auxiliary head 1: NDVI prediction\n        self.ndvi_head = nn.Sequential(\n            nn.Linear(512, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1)\n        )\n        \n        # Auxiliary head 2: Height prediction\n        self.height_head = nn.Sequential(\n            nn.Linear(512, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1)\n        )\n        \n        # Auxiliary head 3: Temperature prediction\n        self.temp_head = nn.Sequential(\n            nn.Linear(512, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1)\n        )\n        \n        # Auxiliary head 4: Rainfall prediction\n        self.rainfall_head = nn.Sequential(\n            nn.Linear(512, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1)\n        )\n    \n    def forward(self, x, return_auxiliary=False):\n        # Extract CNN features\n        features = self.resnet(x)\n        shared = self.shared_features(features)\n        \n        # Main prediction\n        biomass = self.biomass_head(shared)\n        \n        if return_auxiliary:\n            # Auxiliary predictions\n            ndvi = self.ndvi_head(shared)\n            height = self.height_head(shared)\n            temp = self.temp_head(shared)\n            rainfall = self.rainfall_head(shared)\n            return biomass, ndvi, height, temp, rainfall\n        \n        return biomass\n\nprint(\"‚úì AuxiliaryModel defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n# Part 5: Auxiliary Multi-Task Model\n\n**Approach 2**: Train one model with multiple prediction heads.\n\n## Multi-Task Strategy\n- **Main task**: Predict biomass from images (what we care about)\n- **Auxiliary tasks**: Predict NDVI, height, temperature, rainfall from images\n  - Forces the model to learn features relevant to environmental conditions\n  - At test time, ignore auxiliary heads and use main head only\n\n## Loss Weighting\n- Main biomass loss: 0.7\n- Auxiliary NDVI: 0.1\n- Auxiliary height: 0.1  \n- Auxiliary temp: 0.05\n- Auxiliary rainfall: 0.05",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Train Student via Distillation\n\nprint(\"Training Student Model (Knowledge Distillation)...\")\nprint(\"=\"*60)\n\n# Create student model\nstudent_model = StudentModel(num_outputs=5).to(device)\n\n# Load best teacher\nteacher_model.load_state_dict(torch.load('teacher_best.pth'))\nteacher_model.eval()\n\n# Train student\nstudent_history = train_student_distillation(\n    student_model,\n    teacher_model,\n    train_loader_simple,  # Student uses simple image-only loader\n    train_loader_teacher,  # Teacher needs multimodal loader for generating soft targets\n    val_loader_simple,\n    distillation_loss,\n    num_epochs=STUDENT_EPOCHS\n)\n\nprint(\"\\n‚úì Student training complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Train Student via Distillation\n\nprint(\"Training Student Model (Knowledge Distillation)...\")\nprint(\"=\"*60)\n\n# Create student model\nstudent_model = StudentModel(num_outputs=5).to(device)\n\n# Load best teacher\nteacher_model.load_state_dict(torch.load('teacher_best.pth'))\nteacher_model.eval()\n\n# Train student\nstudent_history = train_student_distillation(\n    student_model,\n    teacher_model,\n    train_loader_simple,  # Student uses simple image-only loader\n    train_loader_teacher,  # Teacher needs multimodal loader for generating soft targets\n    val_loader_simple,\n    distillation_loss,\n    num_epochs=15\n)\n\nprint(\"\\n‚úì Student training complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Training function for student distillation\n\ndef train_student_distillation(student, teacher, train_loader_student, train_loader_teacher, \n                                val_loader_simple, criterion, num_epochs=15, lr=3e-4):\n    \"\"\"Train student with knowledge distillation from teacher.\"\"\"\n    teacher.eval()  # Teacher is frozen\n    student.train()\n    \n    optimizer = torch.optim.AdamW(student.parameters(), lr=lr, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n    \n    best_val_loss = float('inf')\n    history = {\n        'train_loss': [], 'train_hard': [], 'train_soft': [], 'train_feature': [],\n        'val_loss': []\n    }\n    \n    for epoch in range(num_epochs):\n        # Training\n        student.train()\n        train_loss = 0\n        train_hard = 0\n        train_soft = 0\n        train_feature = 0\n        \n        # Iterate through both loaders together\n        for batch_student, batch_teacher in tqdm(\n            zip(train_loader_student, train_loader_teacher), \n            desc=f'Epoch {epoch+1}/{num_epochs}',\n            total=min(len(train_loader_student), len(train_loader_teacher))\n        ):\n            # Student forward pass (image only)\n            images = batch_student['image'].to(device)\n            targets = batch_student['targets'].to(device)\n            \n            student_outputs = student(images)\n            student_features = student.get_features(images)\n            \n            # Teacher forward pass (multimodal) - no gradients\n            with torch.no_grad():\n                teacher_images = batch_teacher['image'].to(device)\n                teacher_weather = batch_teacher['weather'].to(device)\n                teacher_ndvi_height = batch_teacher['ndvi_height'].to(device)\n                teacher_state = batch_teacher['state'].to(device)\n                teacher_species = batch_teacher['species'].to(device)\n                \n                teacher_outputs, teacher_features = teacher(\n                    teacher_images, teacher_weather, teacher_ndvi_height, \n                    teacher_state, teacher_species, return_features=True\n                )\n            \n            # Distillation loss\n            loss, hard, soft, feat = criterion(\n                student_outputs, student_features,\n                teacher_outputs, teacher_features,\n                targets\n            )\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * images.size(0)\n            train_hard += hard.item() * images.size(0)\n            train_soft += soft.item() * images.size(0)\n            train_feature += feat.item() * images.size(0)\n        \n        train_loss /= len(train_loader_student.dataset)\n        train_hard /= len(train_loader_student.dataset)\n        train_soft /= len(train_loader_student.dataset)\n        train_feature /= len(train_loader_student.dataset)\n        \n        history['train_loss'].append(train_loss)\n        history['train_hard'].append(train_hard)\n        history['train_soft'].append(train_soft)\n        history['train_feature'].append(train_feature)\n        \n        # Validation (simple image-only)\n        student.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch in val_loader_simple:\n                images = batch['image'].to(device)\n                targets = batch['targets'].to(device)\n                \n                outputs = student(images)\n                loss = F.mse_loss(outputs, targets)\n                val_loss += loss.item() * images.size(0)\n        \n        val_loss /= len(val_loader_simple.dataset)\n        history['val_loss'].append(val_loss)\n        scheduler.step(val_loss)\n        \n        print(f\"  Train Loss: {train_loss:.4f} (hard: {train_hard:.4f}, soft: {train_soft:.4f}, feat: {train_feature:.4f})\")\n        print(f\"  Val Loss: {val_loss:.4f}\")\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(student.state_dict(), 'student_best.pth')\n            print(f\"  ‚úì Saved best model\")\n    \n    return history\n\nprint(\"‚úì Student distillation training function defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Distillation Loss\n\nclass DistillationLoss(nn.Module):\n    \"\"\"Combined loss for knowledge distillation.\"\"\"\n    def __init__(self, temperature=4.0, alpha=0.3, beta=0.5, gamma=0.2):\n        super().__init__()\n        self.temperature = temperature\n        self.alpha = alpha  # Hard loss weight (ground truth)\n        self.beta = beta    # Soft loss weight (teacher predictions)\n        self.gamma = gamma  # Feature loss weight (CNN features)\n        \n        # Competition weights for hard loss\n        self.comp_weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]).to(device)\n    \n    def forward(self, student_outputs, student_features, teacher_outputs, teacher_features, targets):\n        \"\"\"\n        Args:\n            student_outputs: Student predictions (batch, 5)\n            student_features: Student CNN features (batch, 2048)\n            teacher_outputs: Teacher predictions (batch, 5)\n            teacher_features: Teacher CNN features (batch, 2048)\n            targets: Ground truth (batch, 5)\n        \"\"\"\n        # 1. Hard loss: Student vs ground truth (weighted MSE)\n        hard_loss = F.mse_loss(student_outputs, targets, reduction='none')\n        hard_loss = (hard_loss * self.comp_weights).mean()\n        \n        # 2. Soft loss: Student vs teacher with temperature scaling (MSE on soft targets)\n        # For regression, we use MSE instead of KL divergence\n        soft_loss = F.mse_loss(student_outputs / self.temperature, \n                               teacher_outputs / self.temperature)\n        \n        # 3. Feature loss: Match CNN features (cosine similarity)\n        # Normalize features\n        student_feat_norm = F.normalize(student_features, p=2, dim=1)\n        teacher_feat_norm = F.normalize(teacher_features, p=2, dim=1)\n        # Maximize cosine similarity = minimize negative cosine similarity\n        feature_loss = 1 - (student_feat_norm * teacher_feat_norm).sum(dim=1).mean()\n        \n        # Combined loss\n        total_loss = (self.alpha * hard_loss + \n                     self.beta * soft_loss + \n                     self.gamma * feature_loss)\n        \n        return total_loss, hard_loss, soft_loss, feature_loss\n\ndistillation_loss = DistillationLoss(temperature=4.0, alpha=0.3, beta=0.5, gamma=0.2)\nprint(\"‚úì DistillationLoss defined\")\nprint(f\"  Temperature: {distillation_loss.temperature}\")\nprint(f\"  Alpha (hard): {distillation_loss.alpha}\")\nprint(f\"  Beta (soft): {distillation_loss.beta}\")\nprint(f\"  Gamma (feature): {distillation_loss.gamma}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Student Model (same architecture as Baseline)\nStudentModel = BaselineModel  # Reuse the same architecture\n\nprint(\"‚úì StudentModel = BaselineModel (image-only CNN)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n# Part 4: Student Model (Knowledge Distillation)\n\n**Approach 1**: Train an image-only student to mimic the multimodal teacher.\n\n## Distillation Strategy\n1. **Hard Loss**: Student predictions vs ground truth (Œ±=0.3)\n2. **Soft Loss**: Student predictions vs teacher predictions with temperature œÑ=4 (Œ≤=0.5)  \n3. **Feature Loss**: Match CNN features between student and teacher (Œ≥=0.2)\n\nThe student learns to predict biomass from images alone, but guided by the teacher's knowledge of weather/environmental patterns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Train Teacher Model\n\nprint(\"Training Teacher Model (Multimodal)...\")\nprint(\"=\"*60)\n\n# Create dataloaders\ntrain_loader_teacher = DataLoader(train_dataset_teacher, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader_teacher = DataLoader(val_dataset_teacher, batch_size=batch_size, shuffle=False, num_workers=0)\n\n# Create and train teacher\nteacher_model = TeacherModel(\n    num_outputs=5, \n    num_states=len(le_state.classes_), \n    num_species=len(le_species.classes_)\n).to(device)\n\nteacher_history = train_teacher(\n    teacher_model, \n    train_loader_teacher, \n    val_loader_teacher,\n    competition_loss,\n    num_epochs=TEACHER_EPOCHS\n)\n\nprint(\"\\n‚úì Teacher training complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Train Teacher Model\n\nprint(\"Training Teacher Model (Multimodal)...\")\nprint(\"=\"*60)\n\n# Create dataloaders\ntrain_loader_teacher = DataLoader(train_dataset_teacher, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader_teacher = DataLoader(val_dataset_teacher, batch_size=batch_size, shuffle=False, num_workers=0)\n\n# Create and train teacher\nteacher_model = TeacherModel(\n    num_outputs=5, \n    num_states=len(le_state.classes_), \n    num_species=len(le_species.classes_)\n).to(device)\n\nteacher_history = train_teacher(\n    teacher_model, \n    train_loader_teacher, \n    val_loader_teacher,\n    competition_loss,\n    num_epochs=15\n)\n\nprint(\"\\n‚úì Teacher training complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Baseline Model (Image-Only)\n",
    "\n",
    "Simple CNN trained directly on images ‚Üí biomass, with no multimodal data or distillation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}