{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSIRO Biomass Prediction - Kaggle Submission\n",
        "\n",
        "## Model: 4b (Auxiliary Pretrained) - Variation A_Baseline\n",
        "\n",
        "**Validation R\u00b2**: +0.6852\n",
        "\n",
        "### Approach\n",
        "\n",
        "This notebook uses a **two-phase trained model**:\n",
        "\n",
        "**Phase 1 (Auxiliary Pretraining):**\n",
        "- Trained CNN to predict tabular features (NDVI, height, weather, location, species) from images\n",
        "- Forced model to learn visual patterns correlated with tabular data\n",
        "- Achieved 88% state classification accuracy (model learned to \"see\" location!)\n",
        "\n",
        "**Phase 2 (Biomass Fine-tuning):**\n",
        "- Fine-tuned pretrained CNN for biomass prediction\n",
        "- Leverages implicit tabular understanding from Phase 1\n",
        "- **At inference: Only needs images!** (No tabular features required)\n",
        "\n",
        "### Why This Works\n",
        "\n",
        "The auxiliary pretraining teaches the model to extract tabular information from visual cues:\n",
        "- **NDVI** \u2192 Green vegetation color and density\n",
        "- **Height** \u2192 Plant size and structure in image\n",
        "- **Location** \u2192 Terrain, soil color, background features\n",
        "- **Species** \u2192 Leaf shape, growth patterns, color\n",
        "- **Weather** \u2192 Moisture levels, plant stress indicators\n",
        "\n",
        "This \"baked-in\" knowledge improves biomass prediction even though we only use images at test time.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Setup & Imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "print(\"\u2713 Setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Configuration\n",
        "\n",
        "# Target columns (order matters!)\n",
        "TARGET_COLS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "\n",
        "# Target normalization statistics (calculated from full training set)\n",
        "# These values were used during training and must be used to denormalize predictions\n",
        "TARGET_MEANS = torch.tensor([\n",
        "    26.624722,  # Dry_Green_g\n",
        "    12.044548,  # Dry_Dead_g\n",
        "    6.649692,   # Dry_Clover_g\n",
        "    33.274414,  # GDM_g\n",
        "    45.318097   # Dry_Total_g\n",
        "], dtype=torch.float32)\n",
        "\n",
        "TARGET_STDS = torch.tensor([\n",
        "    25.401232,  # Dry_Green_g\n",
        "    12.402007,  # Dry_Dead_g\n",
        "    12.117761,  # Dry_Clover_g\n",
        "    24.935822,  # GDM_g\n",
        "    27.984015   # Dry_Total_g\n",
        "], dtype=torch.float32)\n",
        "\n",
        "# Model configuration (A_Baseline variant)\n",
        "MODEL_CONFIG = {\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.2,\n",
        "    'num_outputs': 5,\n",
        "    'num_states': 4,\n",
        "    'num_species': 15\n",
        "}\n",
        "\n",
        "# Inference batch size\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Targets: {TARGET_COLS}\")\n",
        "print(f\"  Model: AuxiliaryPretrainedModel (A_Baseline)\")\n",
        "print(f\"  Hidden dim: {MODEL_CONFIG['hidden_dim']}\")\n",
        "print(f\"  Dropout: {MODEL_CONFIG['dropout']}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(\"\\n\u2713 Configuration loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Model Architecture\n",
        "\n",
        "class AuxiliaryPretrainedModel(nn.Module):\n",
        "    \"\"\"Model 4b: Two-phase trained model with auxiliary pretraining.\n",
        "    \n",
        "    Phase 1: Trained to predict tabular features (NDVI, height, weather, state, species) from images\n",
        "    Phase 2: Fine-tuned for biomass prediction\n",
        "    \n",
        "    At inference: Only needs image (learned implicit tabular patterns)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_outputs=5, hidden_dim=256, dropout=0.2, num_states=4, num_species=15):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Shared backbone: ResNet18 (pretrained on ImageNet)\n",
        "        self.backbone = models.resnet18(pretrained=False)  # Set to False since we'll load full checkpoint\n",
        "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])  # Remove final FC layer\n",
        "        # Output: 512-dimensional feature vector\n",
        "        \n",
        "        # Phase 1: Auxiliary heads (not used at inference, but needed for checkpoint loading)\n",
        "        self.ndvi_head = nn.Linear(512, 1)                    # Predict NDVI from image\n",
        "        self.height_head = nn.Linear(512, 1)                  # Predict height from image\n",
        "        self.weather_head = nn.Linear(512, 14)                # Predict 14 weather features\n",
        "        self.state_head = nn.Linear(512, num_states)          # Predict location (4 states)\n",
        "        self.species_head = nn.Linear(512, num_species)       # Predict species (15 types)\n",
        "        \n",
        "        # Phase 2: Biomass prediction head (THIS is what we use at inference!)\n",
        "        self.biomass_head = nn.Sequential(\n",
        "            nn.Linear(512, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_outputs)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, mode='biomass'):\n",
        "        \"\"\"Forward pass.\n",
        "        \n",
        "        Args:\n",
        "            x: Input image tensor [B, 3, 224, 224]\n",
        "            mode: 'biomass' for inference (default), 'auxiliary' for phase 1 training\n",
        "        \n",
        "        Returns:\n",
        "            Predicted biomass values [B, 5] (normalized during training, denormalized after inference)\n",
        "        \"\"\"\n",
        "        # Extract features from image\n",
        "        features = self.backbone(x)  # [B, 512, 1, 1]\n",
        "        features = features.flatten(1)  # [B, 512]\n",
        "        \n",
        "        if mode == 'auxiliary':\n",
        "            # Phase 1: Predict tabular features (not used at inference)\n",
        "            return {\n",
        "                'ndvi': self.ndvi_head(features),\n",
        "                'height': self.height_head(features),\n",
        "                'weather': self.weather_head(features),\n",
        "                'state': self.state_head(features),\n",
        "                'species': self.species_head(features)\n",
        "            }\n",
        "        else:  # mode == 'biomass'\n",
        "            # Phase 2: Predict biomass (THIS is inference mode!)\n",
        "            return self.biomass_head(features)  # [B, 5]\n",
        "\n",
        "print(\"\u2713 AuxiliaryPretrainedModel defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Load Model Checkpoint\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Loading model checkpoint...\\n\")\n",
        "\n",
        "# Create model instance\n",
        "model = AuxiliaryPretrainedModel(**MODEL_CONFIG)\n",
        "\n",
        "# Get current working directory for better path resolution\n",
        "cwd = os.getcwd()\n",
        "print(f\"Current working directory: {cwd}\")\n",
        "\n",
        "# Try multiple checkpoint paths (local testing vs Kaggle submission)\n",
        "checkpoint_paths = [\n",
        "    './model4b_A_Baseline_phase2_best.pth',  # Local path (same directory)\n",
        "    'model4b_A_Baseline_phase2_best.pth',    # Try without ./\n",
        "    os.path.join(cwd, 'model4b_A_Baseline_phase2_best.pth'),  # Absolute path\n",
        "    '../input/csiro-biomass-model-weights/model4b_A_Baseline_phase2_best.pth',  # Kaggle input (update dataset name!)\n",
        "    '/kaggle/input/csiro-biomass-model-weights/model4b_A_Baseline_phase2_best.pth',  # Alternative Kaggle path\n",
        "]\n",
        "\n",
        "checkpoint_loaded = False\n",
        "for path in checkpoint_paths:\n",
        "    if Path(path).exists():\n",
        "        print(f\"Found checkpoint at: {path}\")\n",
        "        model.load_state_dict(torch.load(path, map_location=device))\n",
        "        checkpoint_loaded = True\n",
        "        break\n",
        "\n",
        "if not checkpoint_loaded:\n",
        "    print(\"\\n\u274c Could not find model checkpoint!\\n\")\n",
        "    print(\"Tried paths:\")\n",
        "    for p in checkpoint_paths:\n",
        "        exists = \"\u2713\" if Path(p).exists() else \"\u2717\"\n",
        "        print(f\"  {exists} {p}\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FOR KAGGLE SUBMISSION:\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"1. Upload 'model4b_A_Baseline_phase2_best.pth' as a Kaggle Dataset\")\n",
        "    print(\"2. Add the dataset as input to this notebook (click 'Add Data' button)\")\n",
        "    print(\"3. Update the checkpoint_paths list above with your dataset name\")\n",
        "    print(\"   Example: '../input/YOUR-DATASET-NAME/model4b_A_Baseline_phase2_best.pth'\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FOR LOCAL TESTING:\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Ensure 'model4b_A_Baseline_phase2_best.pth' is in:\")\n",
        "    print(f\"  {cwd}\")\n",
        "    print(\"=\"*80)\n",
        "    raise FileNotFoundError(\"Model checkpoint not found\")\n",
        "\n",
        "# Prepare model for inference\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"\\n\u2713 Model loaded successfully!\")\n",
        "print(f\"  Device: {device}\")\n",
        "print(f\"  Mode: Inference (eval mode)\")\n",
        "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Load Test Data\n",
        "\n",
        "print(\"Loading test data...\\n\")\n",
        "\n",
        "# Try multiple test data paths (local testing vs Kaggle submission)\n",
        "test_csv_paths = [\n",
        "    './competition/test.csv',  # Local path\n",
        "    '../input/csiro-biomass-prediction/test.csv',  # Kaggle input path (typical)\n",
        "    '/kaggle/input/csiro-biomass-prediction/test.csv',  # Alternative Kaggle path\n",
        "]\n",
        "\n",
        "test_df = None\n",
        "for path in test_csv_paths:\n",
        "    if Path(path).exists():\n",
        "        print(f\"Found test.csv at: {path}\")\n",
        "        test_df = pd.read_csv(path)\n",
        "        base_path = str(Path(path).parent)\n",
        "        break\n",
        "\n",
        "if test_df is None:\n",
        "    raise FileNotFoundError(\"Could not find test.csv\")\n",
        "\n",
        "print(f\"\\nTest data shape: {test_df.shape}\")\n",
        "print(f\"Columns: {list(test_df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(test_df.head())\n",
        "\n",
        "# Extract unique images from long format\n",
        "# test.csv format: sample_id, image_path, target_name (one row per image\u00d7target combination)\n",
        "test_df['full_image_path'] = test_df['image_path'].apply(lambda x: f\"{base_path}/{x}\")\n",
        "unique_images_df = test_df[['image_path', 'full_image_path']].drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n\u2713 Found {len(unique_images_df)} unique test images\")\n",
        "print(f\"  Total test rows: {len(test_df)} (images \u00d7 targets)\")\n",
        "print(f\"  Expected: {len(unique_images_df)} images \u00d7 5 targets = {len(unique_images_df) * 5} rows\")\n",
        "\n",
        "# Verify all images exist\n",
        "missing_images = []\n",
        "for path in unique_images_df['full_image_path']:\n",
        "    if not Path(path).exists():\n",
        "        missing_images.append(path)\n",
        "\n",
        "if missing_images:\n",
        "    print(f\"\\n\u26a0\ufe0f  WARNING: {len(missing_images)} images not found:\")\n",
        "    for img in missing_images[:5]:\n",
        "        print(f\"  - {img}\")\n",
        "    if len(missing_images) > 5:\n",
        "        print(f\"  ... and {len(missing_images) - 5} more\")\n",
        "else:\n",
        "    print(f\"\\n\u2713 All {len(unique_images_df)} test images found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Create Test Dataset & DataLoader\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    \"\"\"Test dataset for inference (images only, no labels).\"\"\"\n",
        "    \n",
        "    def __init__(self, image_paths):\n",
        "        self.image_paths = image_paths\n",
        "        \n",
        "        # Same transforms used during training (without augmentation)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet stats\n",
        "        ])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "# Create dataset and dataloader\n",
        "test_dataset = TestDataset(unique_images_df['full_image_path'].tolist())\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=False,  # Important: Keep order for matching predictions to images\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "print(f\"\u2713 Test dataset created\")\n",
        "print(f\"  Images: {len(test_dataset)}\")\n",
        "print(f\"  Batches: {len(test_loader)}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Generate Predictions\n",
        "\n",
        "print(\"Generating predictions...\\n\")\n",
        "\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, images in enumerate(tqdm(test_loader, desc='Predicting')):\n",
        "        images = images.to(device)\n",
        "        \n",
        "        # Forward pass (returns normalized predictions)\n",
        "        outputs = model(images, mode='biomass')  # [batch_size, 5]\n",
        "        \n",
        "        # Denormalize to original scale (grams)\n",
        "        outputs_denorm = outputs.cpu() * TARGET_STDS + TARGET_MEANS\n",
        "        \n",
        "        # Clip negative values to 0 (biomass cannot be negative)\n",
        "        outputs_denorm = torch.clamp(outputs_denorm, min=0)\n",
        "        \n",
        "        all_predictions.append(outputs_denorm.numpy())\n",
        "\n",
        "# Stack all predictions\n",
        "all_predictions = np.vstack(all_predictions)  # [num_images, 5]\n",
        "\n",
        "print(f\"\\n\u2713 Predictions generated!\")\n",
        "print(f\"  Shape: {all_predictions.shape} (images \u00d7 targets)\")\n",
        "print(f\"\\nPrediction statistics (grams):\")\n",
        "for i, col in enumerate(TARGET_COLS):\n",
        "    print(f\"  {col:15s}: min={all_predictions[:, i].min():7.2f}g, \"\n",
        "          f\"max={all_predictions[:, i].max():7.2f}g, \"\n",
        "          f\"mean={all_predictions[:, i].mean():7.2f}g\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Create Submission File\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Creating submission file...\\n\")\n",
        "\n",
        "# Convert predictions to long format (one row per sample_id)\n",
        "submission_rows = []\n",
        "\n",
        "for idx, img_path in enumerate(unique_images_df['image_path'].tolist()):\n",
        "    # Extract image ID from path (e.g., 'test/ID1001187975.jpg' -> 'ID1001187975')\n",
        "    image_id = Path(img_path).stem  # Get filename without extension\n",
        "    \n",
        "    # Create one row per target (5 rows per image)\n",
        "    for target_idx, target_name in enumerate(TARGET_COLS):\n",
        "        sample_id = f\"{image_id}__{target_name}\"  # Format: ImageID__TargetName\n",
        "        target_value = all_predictions[idx, target_idx]\n",
        "        \n",
        "        submission_rows.append({\n",
        "            'sample_id': sample_id,\n",
        "            'target': target_value\n",
        "        })\n",
        "\n",
        "# Create DataFrame\n",
        "submission = pd.DataFrame(submission_rows)\n",
        "\n",
        "print(\"Submission DataFrame:\")\n",
        "print(submission.head(10))\n",
        "print(f\"\\nShape: {submission.shape}\")\n",
        "print(f\"Expected: ({len(unique_images_df) * 5}, 2)\")\n",
        "\n",
        "# Quality checks\n",
        "print(f\"\\nQuality checks:\")\n",
        "print(f\"  NaN values: {submission.isna().sum().sum()} \u2713\" if submission.isna().sum().sum() == 0 else f\"  \u26a0\ufe0f  NaN values: {submission.isna().sum().sum()}\")\n",
        "print(f\"  Infinite values: {np.isinf(submission['target']).sum()} \u2713\" if np.isinf(submission['target']).sum() == 0 else f\"  \u26a0\ufe0f  Infinite values: {np.isinf(submission['target']).sum()}\")\n",
        "print(f\"  Negative values: {(submission['target'] < 0).sum()} \u2713\" if (submission['target'] < 0).sum() == 0 else f\"  \u26a0\ufe0f  Negative values: {(submission['target'] < 0).sum()}\")\n",
        "print(f\"  Correct columns: {list(submission.columns) == ['sample_id', 'target']} \u2713\" if list(submission.columns) == ['sample_id', 'target'] else f\"  \u26a0\ufe0f  Columns: {list(submission.columns)}\")\n",
        "\n",
        "# IMPORTANT: Save to current working directory for Kaggle compatibility\n",
        "output_path = 'submission.csv'\n",
        "submission.to_csv(output_path, index=False)\n",
        "\n",
        "# Verify file was created\n",
        "if os.path.exists(output_path):\n",
        "    file_size = os.path.getsize(output_path)\n",
        "    print(f\"\\n\u2705 File verified: {output_path} ({file_size:,} bytes)\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Failed to create {output_path}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"\u2705 SUBMISSION FILE CREATED: submission.csv\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\nFile details:\")\n",
        "print(f\"  Filename: submission.csv (required by Kaggle)\")\n",
        "print(f\"  Location: {os.path.abspath(output_path)}\")\n",
        "print(f\"  Rows: {len(submission):,}\")\n",
        "print(f\"  Images: {len(unique_images_df)}\")\n",
        "print(f\"  Format: Long format (sample_id, target)\")\n",
        "print(f\"\\nModel info:\")\n",
        "print(f\"  Model: AuxiliaryPretrainedModel (4b A_Baseline)\")\n",
        "print(f\"  Validation R\u00b2: +0.6852\")\n",
        "print(f\"  Training: Two-phase (auxiliary pretraining + biomass fine-tuning)\")\n",
        "print(f\"\\nNext steps:\")\n",
        "print(f\"  1. Download submission.csv from notebook output\")\n",
        "print(f\"  2. Submit to Kaggle competition\")\n",
        "print(f\"  3. Check leaderboard for public R\u00b2 score\")\n",
        "print(f\"  4. Compare with validation R\u00b2 (+0.6852)\")\n",
        "print(f\"\\n{'='*80}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}