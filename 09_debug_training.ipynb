{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Debugging: Why is CNN Training Failing?\n",
    "\n",
    "## The Problem\n",
    "\n",
    "**Observations:**\n",
    "- Simple linear regression: **R¬≤ = +0.20** ‚úÖ\n",
    "- CNN with ColorJitter: **R¬≤ = -1.25** ‚ùå\n",
    "- CNN without ColorJitter: **R¬≤ = -1.99** ‚ùå (WORSE!)\n",
    "\n",
    "**Critical insight:** Removing ColorJitter made it WORSE, not better!\n",
    "\n",
    "This suggests the problem is NOT ColorJitter. Something more fundamental is broken.\n",
    "\n",
    "## Investigation Plan\n",
    "\n",
    "1. **Data Loading**: Are images and targets loading correctly?\n",
    "2. **Model Forward Pass**: Are predictions in the right range?\n",
    "3. **Loss Calculation**: Is loss computing correctly?\n",
    "4. **Gradient Flow**: Are gradients flowing through the network?\n",
    "5. **Normalization**: Is ImageNet normalization appropriate?\n",
    "6. **Overfitting Test**: Can model memorize a single batch?\n",
    "7. **Target Scale**: Are target values on the right scale?\n",
    "\n",
    "Let's systematically check each component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"‚úì Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_enriched = pd.read_csv('competition/train_enriched.csv')\n",
    "train_enriched['Sampling_Date'] = pd.to_datetime(train_enriched['Sampling_Date'])\n",
    "train_enriched['full_image_path'] = train_enriched['image_path'].apply(lambda x: f'competition/{x}')\n",
    "\n",
    "target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "competition_weights = [0.1, 0.1, 0.1, 0.2, 0.5]\n",
    "\n",
    "train_data, val_data = train_test_split(train_enriched, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Data loaded: {len(train_data)} train, {len(val_data)} val\")\n",
    "print(f\"Targets: {target_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 1: Inspect Single Batch - Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple dataset (no normalization first)\n",
    "class DebugDataset(Dataset):\n",
    "    def __init__(self, dataframe, normalize=False):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        if normalize:\n",
    "            # ImageNet normalization\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            # No normalization - just convert to tensor\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['full_image_path']).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        targets = torch.tensor(row[target_cols].values.astype('float32'), dtype=torch.float32)\n",
    "        return {'image': img, 'targets': targets, 'path': row['full_image_path']}\n",
    "\n",
    "# Create dataset WITHOUT normalization\n",
    "debug_dataset = DebugDataset(train_data, normalize=False)\n",
    "debug_loader = DataLoader(debug_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Get first batch\n",
    "batch = next(iter(debug_loader))\n",
    "images = batch['image']\n",
    "targets = batch['targets']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BATCH INSPECTION (No Normalization)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nBatch shape: {images.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")\n",
    "\n",
    "print(f\"\\nImage statistics (should be [0, 1] after ToTensor):\")\n",
    "print(f\"  Min: {images.min().item():.4f}\")\n",
    "print(f\"  Max: {images.max().item():.4f}\")\n",
    "print(f\"  Mean: {images.mean().item():.4f}\")\n",
    "print(f\"  Std: {images.std().item():.4f}\")\n",
    "\n",
    "print(f\"\\nTarget statistics (biomass in grams):\")\n",
    "for i, col in enumerate(target_cols):\n",
    "    print(f\"  {col}:\")\n",
    "    print(f\"    Min: {targets[:, i].min().item():.2f}g\")\n",
    "    print(f\"    Max: {targets[:, i].max().item():.2f}g\")\n",
    "    print(f\"    Mean: {targets[:, i].mean().item():.2f}g\")\n",
    "    print(f\"    Std: {targets[:, i].std().item():.2f}g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN or Inf in targets\n",
    "print(\"\\nData Quality Checks:\")\n",
    "print(f\"  NaN in images: {torch.isnan(images).any().item()}\")\n",
    "print(f\"  Inf in images: {torch.isinf(images).any().item()}\")\n",
    "print(f\"  NaN in targets: {torch.isnan(targets).any().item()}\")\n",
    "print(f\"  Inf in targets: {torch.isinf(targets).any().item()}\")\n",
    "\n",
    "if torch.isnan(targets).any() or torch.isinf(targets).any():\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Found NaN or Inf in targets!\")\n",
    "else:\n",
    "    print(\"\\n‚úì No NaN or Inf values detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first image from batch\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Show first image\n",
    "img_to_show = images[0].permute(1, 2, 0).numpy()\n",
    "axes[0].imshow(img_to_show)\n",
    "axes[0].set_title('First Image (No Normalization)', fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Show target values\n",
    "target_vals = targets[0].numpy()\n",
    "axes[1].bar(range(5), target_vals, color=['green', 'brown', 'lightgreen', 'blue', 'purple'])\n",
    "axes[1].set_xticks(range(5))\n",
    "axes[1].set_xticklabels(['Green', 'Dead', 'Clover', 'GDM', 'Total'], rotation=45)\n",
    "axes[1].set_ylabel('Biomass (g)')\n",
    "axes[1].set_title('Target Values for First Image', fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Show RGB histogram\n",
    "for c, color in enumerate(['red', 'green', 'blue']):\n",
    "    hist = images[0, c].flatten().numpy()\n",
    "    axes[2].hist(hist, bins=50, alpha=0.5, label=color.upper(), color=color)\n",
    "axes[2].set_xlabel('Pixel Value')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('RGB Histogram (First Image)', fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Batch visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 2: Compare ImageNet vs Custom Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate actual mean/std of training images\n",
    "print(\"Calculating actual image statistics from training set...\")\n",
    "print(\"This may take 2-3 minutes...\\n\")\n",
    "\n",
    "# Sample 100 images to calculate stats\n",
    "sample_size = min(100, len(train_data))\n",
    "sample_indices = np.random.choice(len(train_data), sample_size, replace=False)\n",
    "\n",
    "all_pixels = []\n",
    "for idx in tqdm(sample_indices):\n",
    "    img_path = train_data.iloc[idx]['full_image_path']\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
    "    all_pixels.append(img_array.reshape(-1, 3))\n",
    "\n",
    "all_pixels = np.vstack(all_pixels)\n",
    "actual_mean = all_pixels.mean(axis=0)\n",
    "actual_std = all_pixels.std(axis=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NORMALIZATION COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nImageNet normalization (what we're using):\")\n",
    "print(f\"  Mean: [0.485, 0.456, 0.406]\")\n",
    "print(f\"  Std:  [0.229, 0.224, 0.225]\")\n",
    "\n",
    "print(f\"\\nActual training data statistics:\")\n",
    "print(f\"  Mean: [{actual_mean[0]:.3f}, {actual_mean[1]:.3f}, {actual_mean[2]:.3f}]\")\n",
    "print(f\"  Std:  [{actual_std[0]:.3f}, {actual_std[1]:.3f}, {actual_std[2]:.3f}]\")\n",
    "\n",
    "# Calculate difference\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "mean_diff = np.abs(actual_mean - imagenet_mean)\n",
    "std_diff = np.abs(actual_std - imagenet_std)\n",
    "\n",
    "print(f\"\\nDifference:\")\n",
    "print(f\"  Mean diff: [{mean_diff[0]:.3f}, {mean_diff[1]:.3f}, {mean_diff[2]:.3f}]\")\n",
    "print(f\"  Std diff:  [{std_diff[0]:.3f}, {std_diff[1]:.3f}, {std_diff[2]:.3f}]\")\n",
    "\n",
    "if np.max(mean_diff) > 0.1 or np.max(std_diff) > 0.05:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Large difference between ImageNet and actual statistics!\")\n",
    "    print(\"   ImageNet normalization might be inappropriate for this data.\")\n",
    "    print(\"   Recommendation: Use custom normalization based on actual data.\")\n",
    "else:\n",
    "    print(\"\\n‚úì ImageNet normalization appears reasonable for this data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 3: Model Forward Pass - Prediction Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_outputs=5):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model = SimpleModel(num_outputs=5).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úì Model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with normalized images\n",
    "debug_dataset_norm = DebugDataset(train_data, normalize=True)\n",
    "debug_loader_norm = DataLoader(debug_dataset_norm, batch_size=16, shuffle=False)\n",
    "batch_norm = next(iter(debug_loader_norm))\n",
    "\n",
    "images_norm = batch_norm['image'].to(device)\n",
    "targets_batch = batch_norm['targets']\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    predictions = model(images_norm)\n",
    "\n",
    "predictions_cpu = predictions.cpu()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL FORWARD PASS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nPrediction statistics (BEFORE training):\")\n",
    "print(f\"  Shape: {predictions_cpu.shape}\")\n",
    "print(f\"  Min: {predictions_cpu.min().item():.4f}\")\n",
    "print(f\"  Max: {predictions_cpu.max().item():.4f}\")\n",
    "print(f\"  Mean: {predictions_cpu.mean().item():.4f}\")\n",
    "print(f\"  Std: {predictions_cpu.std().item():.4f}\")\n",
    "\n",
    "print(f\"\\nPer-target predictions:\")\n",
    "for i, col in enumerate(target_cols):\n",
    "    pred_mean = predictions_cpu[:, i].mean().item()\n",
    "    pred_std = predictions_cpu[:, i].std().item()\n",
    "    target_mean = targets_batch[:, i].mean().item()\n",
    "    target_std = targets_batch[:, i].std().item()\n",
    "    \n",
    "    print(f\"\\n  {col}:\")\n",
    "    print(f\"    Pred:   {pred_mean:8.2f} ¬± {pred_std:6.2f}\")\n",
    "    print(f\"    Target: {target_mean:8.2f} ¬± {target_std:6.2f}\")\n",
    "    print(f\"    Diff:   {abs(pred_mean - target_mean):8.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pred_range = predictions_cpu.max().item() - predictions_cpu.min().item()\n",
    "target_range = targets_batch.max().item() - targets_batch.min().item()\n",
    "\n",
    "print(f\"\\nPrediction range: {pred_range:.2f}\")\n",
    "print(f\"Target range: {target_range:.2f}\")\n",
    "\n",
    "if abs(predictions_cpu.mean().item()) < 1.0:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Predictions are very close to zero!\")\n",
    "    print(\"   Model might not be initialized properly.\")\n",
    "    print(\"   Expected: Predictions should be in range [0, 200] like targets.\")\n",
    "elif pred_range < 10:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Predictions have very small range!\")\n",
    "    print(\"   Model is outputting nearly identical values for all samples.\")\n",
    "    print(\"   This suggests model hasn't learned to differentiate.\")\n",
    "else:\n",
    "    print(\"\\n‚úì Prediction range looks reasonable for untrained model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 4: Loss Calculation - Manual Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loss function\n",
    "class CompetitionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]).to(device)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        mse = F.mse_loss(pred, target, reduction='none')\n",
    "        weighted_mse = (mse * self.weights).mean()\n",
    "        return weighted_mse\n",
    "\n",
    "criterion = CompetitionLoss()\n",
    "\n",
    "# Calculate loss\n",
    "loss = criterion(predictions, targets_batch.to(device))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOSS CALCULATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nCompetition loss: {loss.item():.4f}\")\n",
    "\n",
    "# Manual calculation per target\n",
    "print(f\"\\nPer-target losses:\")\n",
    "for i, col in enumerate(target_cols):\n",
    "    pred_i = predictions_cpu[:, i]\n",
    "    target_i = targets_batch[:, i]\n",
    "    \n",
    "    # Manual MSE\n",
    "    mse_i = ((pred_i - target_i) ** 2).mean().item()\n",
    "    weighted_mse_i = mse_i * competition_weights[i]\n",
    "    \n",
    "    print(f\"\\n  {col}:\")\n",
    "    print(f\"    MSE: {mse_i:.2f}\")\n",
    "    print(f\"    Weighted MSE: {weighted_mse_i:.2f} (weight: {competition_weights[i]})\")\n",
    "\n",
    "# Compare plain MSE\n",
    "plain_mse = F.mse_loss(predictions, targets_batch.to(device))\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Competition loss (weighted): {loss.item():.4f}\")\n",
    "print(f\"  Plain MSE (unweighted): {plain_mse.item():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if loss.item() > 10000:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Loss is extremely high!\")\n",
    "    print(\"   This suggests predictions are very far from targets.\")\n",
    "    print(\"   Expected loss for random initialization: 1000-5000\")\n",
    "elif loss.item() < 100:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Loss is very low for untrained model!\")\n",
    "    print(\"   This is suspicious. Check if loss is calculating correctly.\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Loss value ({loss.item():.2f}) is in expected range for untrained model.\")\n",
    "    print(\"  Expected: 1000-5000 for random predictions on biomass data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 5: Gradient Flow Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test gradient flow\n",
    "model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Forward pass\n",
    "predictions = model(images_norm)\n",
    "loss = criterion(predictions, targets_batch.to(device))\n",
    "\n",
    "# Backward pass\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GRADIENT FLOW ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check gradients\n",
    "print(f\"\\nGradient statistics for each layer:\")\n",
    "total_grad_norm = 0\n",
    "zero_grad_layers = 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        grad_norm = param.grad.norm().item()\n",
    "        total_grad_norm += grad_norm\n",
    "        \n",
    "        # Only show FC layers (ResNet conv layers would be too many)\n",
    "        if 'fc' in name:\n",
    "            print(f\"  {name:40s}: {grad_norm:.6f}\")\n",
    "        \n",
    "        if grad_norm < 1e-8:\n",
    "            zero_grad_layers += 1\n",
    "    else:\n",
    "        print(f\"  {name:40s}: No gradient!\")\n",
    "\n",
    "print(f\"\\nTotal gradient norm: {total_grad_norm:.4f}\")\n",
    "print(f\"Layers with zero gradient: {zero_grad_layers}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if total_grad_norm < 1e-6:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Gradients are extremely small or zero!\")\n",
    "    print(\"   Possible causes:\")\n",
    "    print(\"     - Vanishing gradient problem\")\n",
    "    print(\"     - Loss not connected to model parameters\")\n",
    "    print(\"     - Learning rate too low\")\n",
    "elif total_grad_norm > 1000:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Gradients are exploding!\")\n",
    "    print(\"   Possible causes:\")\n",
    "    print(\"     - Learning rate too high\")\n",
    "    print(\"     - Unstable loss function\")\n",
    "    print(\"   Recommendation: Use gradient clipping or lower learning rate\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Gradient norms are in reasonable range ({total_grad_norm:.4f}).\")\n",
    "    print(\"  Gradients are flowing through the network.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 6: Weight Update Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store weight before update\n",
    "fc_weight_before = model.resnet.fc[0].weight.data.clone()\n",
    "\n",
    "# Take optimizer step\n",
    "optimizer.step()\n",
    "\n",
    "# Check weight after update\n",
    "fc_weight_after = model.resnet.fc[0].weight.data\n",
    "weight_change = (fc_weight_after - fc_weight_before).abs().mean().item()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WEIGHT UPDATE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nFC layer (first layer):\")\n",
    "print(f\"  Weight before update: mean={fc_weight_before.mean().item():.6f}, std={fc_weight_before.std().item():.6f}\")\n",
    "print(f\"  Weight after update:  mean={fc_weight_after.mean().item():.6f}, std={fc_weight_after.std().item():.6f}\")\n",
    "print(f\"  Mean absolute change: {weight_change:.8f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if weight_change < 1e-8:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Weights are not changing!\")\n",
    "    print(\"   Possible causes:\")\n",
    "    print(\"     - Learning rate too low (current: 1e-4)\")\n",
    "    print(\"     - Gradients too small\")\n",
    "    print(\"     - Optimizer issue\")\n",
    "    print(\"   Recommendation: Increase learning rate to 1e-3 or 3e-4\")\n",
    "elif weight_change > 0.1:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Weights changing too much in one step!\")\n",
    "    print(\"   Learning rate might be too high.\")\n",
    "    print(\"   Recommendation: Lower learning rate\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Weights are updating normally ({weight_change:.8f} change per step).\")\n",
    "    print(\"  Optimizer is working correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 7: Overfit Single Batch (Critical Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"OVERFITTING TEST: Can model memorize a single batch?\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis test trains on just 1 batch for 100 steps.\")\n",
    "print(\"A working model should achieve near-zero loss.\")\n",
    "print(\"If it can't, the model architecture is broken.\\n\")\n",
    "\n",
    "# Create fresh model\n",
    "test_model = SimpleModel(num_outputs=5).to(device)\n",
    "test_optimizer = torch.optim.AdamW(test_model.parameters(), lr=1e-3)  # Higher LR for faster overfitting\n",
    "test_criterion = CompetitionLoss()\n",
    "\n",
    "# Get one batch\n",
    "test_batch = next(iter(debug_loader_norm))\n",
    "test_images = test_batch['image'].to(device)\n",
    "test_targets = test_batch['targets'].to(device)\n",
    "\n",
    "# Train on this batch for 100 steps\n",
    "losses = []\n",
    "r2_scores_over_time = []\n",
    "\n",
    "test_model.train()\n",
    "for step in range(100):\n",
    "    # Forward\n",
    "    pred = test_model(test_images)\n",
    "    loss = test_criterion(pred, test_targets)\n",
    "    \n",
    "    # Backward\n",
    "    test_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    test_optimizer.step()\n",
    "    \n",
    "    # Track\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Calculate R¬≤ every 10 steps\n",
    "    if step % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            target_np = test_targets.cpu().numpy()\n",
    "            r2_total = sum([competition_weights[i] * r2_score(target_np[:, i], pred_np[:, i]) for i in range(5)])\n",
    "            r2_scores_over_time.append(r2_total)\n",
    "            print(f\"Step {step:3d}: Loss = {loss.item():.4f}, R¬≤ = {r2_total:+.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    final_pred = test_model(test_images)\n",
    "    final_loss = test_criterion(final_pred, test_targets)\n",
    "    \n",
    "    pred_np = final_pred.cpu().numpy()\n",
    "    target_np = test_targets.cpu().numpy()\n",
    "    final_r2 = sum([competition_weights[i] * r2_score(target_np[:, i], pred_np[:, i]) for i in range(5)])\n",
    "\n",
    "print(f\"\\nFinal results after 100 steps:\")\n",
    "print(f\"  Loss: {final_loss.item():.4f}\")\n",
    "print(f\"  R¬≤: {final_r2:+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if final_r2 > 0.9:\n",
    "    print(\"\\n‚úÖ SUCCESS: Model can overfit a single batch!\")\n",
    "    print(\"   This proves the model architecture is working.\")\n",
    "    print(\"   The problem is likely:\")\n",
    "    print(\"     - Learning rate too low for full training\")\n",
    "    print(\"     - Need more epochs\")\n",
    "    print(\"     - Regularization too strong (dropout, weight decay)\")\n",
    "elif final_r2 > 0.5:\n",
    "    print(\"\\n‚ö†Ô∏è  PARTIAL SUCCESS: Model is learning but slowly\")\n",
    "    print(\"   Model architecture works but might not be optimal.\")\n",
    "    print(\"   Recommendations:\")\n",
    "    print(\"     - Increase learning rate\")\n",
    "    print(\"     - Simplify architecture (remove BatchNorm/Dropout)\")\n",
    "elif final_r2 > 0.0:\n",
    "    print(\"\\n‚ö†Ô∏è  POOR PERFORMANCE: Model learning very slowly\")\n",
    "    print(\"   Issues:\")\n",
    "    print(\"     - Learning rate too low\")\n",
    "    print(\"     - Model architecture might be problematic\")\n",
    "    print(\"     - Check normalization\")\n",
    "else:\n",
    "    print(\"\\n‚ùå FAILURE: Model CANNOT overfit a single batch!\")\n",
    "    print(\"   This is a critical failure. The model architecture is broken.\")\n",
    "    print(\"   Possible causes:\")\n",
    "    print(\"     - Wrong input/output shapes\")\n",
    "    print(\"     - Loss function not connected properly\")\n",
    "    print(\"     - Severe numerical issues (NaN/Inf)\")\n",
    "    print(\"     - Model too simple for the task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overfitting progress\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "ax = axes[0]\n",
    "ax.plot(losses, linewidth=2)\n",
    "ax.set_xlabel('Step', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Loss During Overfitting Test (100 steps)', fontsize=14, fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# R¬≤ curve\n",
    "ax = axes[1]\n",
    "ax.plot(range(0, 100, 10), r2_scores_over_time, 'o-', linewidth=2, markersize=8)\n",
    "ax.axhline(y=0.0, color='gray', linestyle='--', label='Baseline')\n",
    "ax.axhline(y=0.9, color='green', linestyle='--', label='Target (R¬≤=0.9)')\n",
    "ax.set_xlabel('Step', fontsize=12)\n",
    "ax.set_ylabel('R¬≤ Score', fontsize=12)\n",
    "ax.set_title('R¬≤ During Overfitting Test', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('overfit_test.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Overfitting test complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test 8: Target Scale Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target value scales across dataset\n",
    "print(\"=\"*80)\n",
    "print(\"TARGET SCALE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in target_cols:\n",
    "    values = train_data[col].values\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: {values.min():.2f}g\")\n",
    "    print(f\"  Max: {values.max():.2f}g\")\n",
    "    print(f\"  Range: {values.max() - values.min():.2f}g\")\n",
    "    print(f\"  Mean: {values.mean():.2f}g\")\n",
    "    print(f\"  Std: {values.std():.2f}g\")\n",
    "    print(f\"  Coefficient of variation: {values.std() / values.mean():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nDifferent targets have very different scales:\")\n",
    "print(\"  - Dry_Clover_g often ~0-20g (low)\")\n",
    "print(\"  - Dry_Total_g typically 20-150g (high)\")\n",
    "print(\"\\nThis scale difference might make training harder.\")\n",
    "print(\"\\nOptions:\")\n",
    "print(\"  1. Normalize targets (StandardScaler) - Model predicts normalized, denormalize for eval\")\n",
    "print(\"  2. Use per-target learning rates (not easy in PyTorch)\")\n",
    "print(\"  3. Use different loss weights (already doing this)\")\n",
    "print(\"  4. Keep as-is but use longer training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: Root Cause Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DEBUGGING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìã TESTS COMPLETED:\")\n",
    "print(\"  1. ‚úì Data loading inspection\")\n",
    "print(\"  2. ‚úì ImageNet vs custom normalization\")\n",
    "print(\"  3. ‚úì Model forward pass\")\n",
    "print(\"  4. ‚úì Loss calculation\")\n",
    "print(\"  5. ‚úì Gradient flow\")\n",
    "print(\"  6. ‚úì Weight updates\")\n",
    "print(\"  7. ‚úì Overfit single batch test (CRITICAL)\")\n",
    "print(\"  8. ‚úì Target scale analysis\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nReview the results above to identify:\")\n",
    "print(\"\\n1. Can model overfit single batch?\")\n",
    "print(\"   - If YES: Architecture works, need better training setup\")\n",
    "print(\"   - If NO: Architecture broken, need to fix model\")\n",
    "\n",
    "print(\"\\n2. Are gradients flowing?\")\n",
    "print(\"   - Check gradient norm (should be 1-100 range)\")\n",
    "print(\"   - If too small: Learning rate too low or vanishing gradients\")\n",
    "print(\"   - If too large: Learning rate too high or exploding gradients\")\n",
    "\n",
    "print(\"\\n3. Is ImageNet normalization appropriate?\")\n",
    "print(\"   - Check difference between ImageNet and actual data stats\")\n",
    "print(\"   - If large difference: Use custom normalization\")\n",
    "\n",
    "print(\"\\n4. Are predictions in right range?\")\n",
    "print(\"   - Should be roughly 0-200g like targets\")\n",
    "print(\"   - If very different scale: Initialization or architecture issue\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDED NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nBased on the findings above, prioritize:\")\n",
    "print(\"\\n1. If model CAN overfit single batch:\")\n",
    "print(\"   ‚Üí Increase learning rate to 3e-4 or 5e-4\")\n",
    "print(\"   ‚Üí Train for 15-20 epochs instead of 5\")\n",
    "print(\"   ‚Üí Remove or reduce dropout/weight decay\")\n",
    "\n",
    "print(\"\\n2. If gradients are very small:\")\n",
    "print(\"   ‚Üí Increase learning rate by 10√ó\")\n",
    "print(\"   ‚Üí Check if BatchNorm is causing issues\")\n",
    "print(\"   ‚Üí Try simpler architecture without BatchNorm\")\n",
    "\n",
    "print(\"\\n3. If ImageNet normalization is very different:\")\n",
    "print(\"   ‚Üí Use custom normalization based on actual data\")\n",
    "print(\"   ‚Üí Retrain with correct normalization\")\n",
    "\n",
    "print(\"\\n4. If model CANNOT overfit single batch:\")\n",
    "print(\"   ‚Üí Major architecture problem\")\n",
    "print(\"   ‚Üí Try even simpler model (linear layer on features)\")\n",
    "print(\"   ‚Üí Check for implementation bugs\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì Debugging complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
