{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2: Test DenseNet Submission",
    "",
    "## Goal",
    "Submit DenseNet (Val RÂ²=0.6605) to Kaggle to test the validation-test gap theory.",
    "",
    "## Hypothesis",
    "The validation-test gap (-0.175) affects all models similarly.",
    "",
    "**Expected**: DenseNet Kaggle RÂ² ~ 0.49 (worse than baseline 0.51)",
    "",
    "This would confirm that even \"good\" validation scores don't guarantee good Kaggle scores.",
    "",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd",
    "import numpy as np",
    "import torch",
    "import torch.nn as nn",
    "from torch.utils.data import Dataset, DataLoader",
    "import torchvision.transforms as transforms",
    "import torchvision.models as models",
    "from PIL import Image",
    "from tqdm.auto import tqdm",
    "from datetime import datetime",
    "",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
    "print(f\"Device: {device}\")",
    "",
    "TARGET_COLS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Define Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load test data",
    "test_df = pd.read_csv('../../competition/test.csv')",
    "test_df['full_image_path'] = test_df['image_path'].apply(lambda x: f'../../competition/{x}')",
    "unique_images = test_df[['image_path', 'full_image_path']].drop_duplicates()",
    "print(f\"Test images: {len(unique_images)}\")",
    "",
    "# Test dataset",
    "class TestDataset(Dataset):",
    "    def __init__(self, image_paths):",
    "        self.image_paths = image_paths",
    "        self.transform = transforms.Compose([",
    "            transforms.Resize((224, 224)),",
    "            transforms.ToTensor(),",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])",
    "        ])",
    "    def __len__(self):",
    "        return len(self.image_paths)",
    "    def __getitem__(self, idx):",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')",
    "        return self.transform(img)",
    "",
    "test_dataset = TestDataset(unique_images['full_image_path'].tolist())",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)",
    "print(f\"âœ“ Test dataset: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Define model (must match training architecture)\nclass AuxiliaryPretrainedModel(nn.Module):\n    def __init__(self, num_outputs=5, hidden_dim=256, dropout=0.2, num_states=4, num_species=15):\n        super().__init__()\n        # DenseNet121 backbone\n        densenet = models.densenet121(pretrained=True)\n        self.backbone = nn.Sequential(\n            densenet.features, nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1))\n        )\n        feature_dim = 1024\n        \n        # Auxiliary heads (required for loading checkpoint, even though we won't use them)\n        self.ndvi_head = nn.Linear(feature_dim, 1)\n        self.height_head = nn.Linear(feature_dim, 1)\n        self.weather_head = nn.Linear(feature_dim, 14)\n        self.state_head = nn.Linear(feature_dim, num_states)\n        self.species_head = nn.Linear(feature_dim, num_species)\n        \n        # Biomass head (this is what we actually use)\n        self.biomass_head = nn.Sequential(\n            nn.Linear(feature_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_outputs)\n        )\n    \n    def forward(self, x, mode='biomass'):\n        features = self.backbone(x).flatten(1)\n        if mode == 'auxiliary':\n            return {\n                'ndvi': self.ndvi_head(features),\n                'height': self.height_head(features),\n                'weather': self.weather_head(features),\n                'state': self.state_head(features),\n                'species': self.species_head(features)\n            }\n        else:\n            return self.biomass_head(features)\n\nmodel = AuxiliaryPretrainedModel()\nprint(\"âœ“ Model defined (with auxiliary heads for checkpoint compatibility)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint & Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load trained checkpoint",
    "checkpoint_path = '../../model4b_4b8_DenseNet_phase2_best.pth'",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))",
    "model = model.to(device)",
    "model.eval()",
    "print(f\"âœ“ Loaded: {checkpoint_path}\")",
    "",
    "# Normalization stats (from training)",
    "target_means = torch.tensor([27.49, 12.01, 6.26, 33.74, 45.75])",
    "target_stds = torch.tensor([26.19, 12.50, 11.75, 25.62, 28.86])",
    "",
    "print(\"\\nGenerating predictions...\")",
    "all_preds = []",
    "with torch.no_grad():",
    "    for images in tqdm(test_loader):",
    "        images = images.to(device)",
    "        outputs = model(images)",
    "        outputs_denorm = outputs.cpu() * target_stds + target_means",
    "        outputs_denorm = torch.clamp(outputs_denorm, min=0)",
    "        all_preds.append(outputs_denorm.numpy())",
    "",
    "predictions = np.vstack(all_preds)",
    "print(f\"âœ“ Predictions: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create submission in long format",
    "submission_rows = []",
    "for idx, img_path in enumerate(unique_images['image_path'].tolist()):",
    "    image_id = img_path.split('/')[-1].replace('.jpg', '')",
    "    for target_idx, target_name in enumerate(TARGET_COLS):",
    "        submission_rows.append({",
    "            'sample_id': f\"{image_id}__{target_name}\",",
    "            'target': predictions[idx, target_idx]",
    "        })",
    "",
    "submission = pd.DataFrame(submission_rows)",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')",
    "filename = f'../../submission_densenet_{timestamp}.csv'",
    "submission.to_csv(filename, index=False)",
    "",
    "print(f\"\\nâœ… Submission saved: {filename}\")",
    "print(f\"   Rows: {len(submission)}\")",
    "print(f\"   Expected Kaggle RÂ²: ~0.49 (validation was 0.6605)\")",
    "print(f\"\\nðŸ“Š If Kaggle score < 0.51 â†’ Confirms validation-test gap theory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}