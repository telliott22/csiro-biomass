{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Feature Engineering\n",
    "\n",
    "Enriching the dataset with weather and environmental features:\n",
    "- Historical rainfall and temperature data\n",
    "- Evapotranspiration estimates\n",
    "- Weather anomalies (deviation from long-term means)\n",
    "- Daylength and seasonal features\n",
    "- NDVI anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom weather API\n",
    "from weather_api import (\n",
    "    WeatherAPIClient, \n",
    "    calculate_daylength, \n",
    "    get_southern_hemisphere_season\n",
    ")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('competition/train.csv')\n",
    "\n",
    "# Convert to wide format\n",
    "train_wide = train_df.pivot_table(\n",
    "    index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "    columns='target_name',\n",
    "    values='target'\n",
    ").reset_index()\n",
    "\n",
    "# Convert date\n",
    "train_wide['Sampling_Date'] = pd.to_datetime(train_wide['Sampling_Date'])\n",
    "\n",
    "print(f\"Training samples: {len(train_wide)}\")\n",
    "print(f\"\\nStates: {train_wide['State'].value_counts().to_dict()}\")\n",
    "print(f\"\\nDate range: {train_wide['Sampling_Date'].min()} to {train_wide['Sampling_Date'].max()}\")\n",
    "train_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Weather API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weather client with caching\n",
    "weather_client = WeatherAPIClient(cache_dir='weather_cache')\n",
    "\n",
    "print(\"Weather API Client initialized\")\n",
    "print(\"\\nRepresentative locations:\")\n",
    "for state, info in weather_client.LOCATIONS.items():\n",
    "    print(f\"  {state}: {info['name']} ({info['lat']:.2f}°, {info['lon']:.2f}°)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch Weather Data for All States\n",
    "\n",
    "This will fetch historical weather data for the date range in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overall date range (with buffer for rolling calculations)\n",
    "min_date = train_wide['Sampling_Date'].min()\n",
    "max_date = train_wide['Sampling_Date'].max()\n",
    "\n",
    "print(f\"Fetching weather data from {min_date.date()} to {max_date.date()}\")\n",
    "print(\"(includes 30 days before for rolling averages)\\n\")\n",
    "\n",
    "# Fetch data for each state\n",
    "weather_data = {}\n",
    "for state in train_wide['State'].unique():\n",
    "    print(f\"\\n{state}:\")\n",
    "    df = weather_client.fetch_weather_data(\n",
    "        state=state,\n",
    "        start_date=min_date.strftime('%Y-%m-%d'),\n",
    "        end_date=max_date.strftime('%Y-%m-%d'),\n",
    "        days_before=30\n",
    "    )\n",
    "    weather_data[state] = df\n",
    "    print(f\"  → {len(df)} days fetched\")\n",
    "\n",
    "print(\"\\n✓ All weather data fetched and cached!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview weather data\n",
    "print(\"Sample weather data for Tasmania:\")\n",
    "weather_data['Tas'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Rolling Weather Features\n",
    "\n",
    "Create 7-day and 30-day rolling averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate rolling weather features.\n",
    "    \n",
    "    Args:\n",
    "        df: Weather dataframe with daily data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with rolling features added\n",
    "    \"\"\"\n",
    "    df = df.copy().sort_values('date')\n",
    "    \n",
    "    # 7-day rolling features\n",
    "    df['rainfall_7d'] = df['precipitation'].rolling(window=7, min_periods=1).sum()\n",
    "    df['temp_max_7d'] = df['temp_max'].rolling(window=7, min_periods=1).mean()\n",
    "    df['temp_min_7d'] = df['temp_min'].rolling(window=7, min_periods=1).mean()\n",
    "    df['temp_mean_7d'] = df['temp_mean'].rolling(window=7, min_periods=1).mean()\n",
    "    df['et0_7d'] = df['et0'].rolling(window=7, min_periods=1).sum()\n",
    "    \n",
    "    # 30-day rolling features\n",
    "    df['rainfall_30d'] = df['precipitation'].rolling(window=30, min_periods=1).sum()\n",
    "    df['temp_mean_30d'] = df['temp_mean'].rolling(window=30, min_periods=1).mean()\n",
    "    df['et0_30d'] = df['et0'].rolling(window=30, min_periods=1).sum()\n",
    "    \n",
    "    # Temperature range (daily and 7-day avg)\n",
    "    df['temp_range'] = df['temp_max'] - df['temp_min']\n",
    "    df['temp_range_7d'] = df['temp_range'].rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    # Days since significant rain (>5mm)\n",
    "    df['significant_rain'] = (df['precipitation'] > 5).astype(int)\n",
    "    df['days_since_rain'] = 0\n",
    "    \n",
    "    days_counter = 0\n",
    "    days_since_rain = []\n",
    "    for has_rain in df['significant_rain']:\n",
    "        if has_rain:\n",
    "            days_counter = 0\n",
    "        else:\n",
    "            days_counter += 1\n",
    "        days_since_rain.append(days_counter)\n",
    "    \n",
    "    df['days_since_rain'] = days_since_rain\n",
    "    \n",
    "    # Water balance (rainfall - ET)\n",
    "    df['water_balance_7d'] = df['rainfall_7d'] - df['et0_7d']\n",
    "    df['water_balance_30d'] = df['rainfall_30d'] - df['et0_30d']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Calculate rolling features for each state\n",
    "print(\"Calculating rolling features...\\n\")\n",
    "for state in weather_data.keys():\n",
    "    weather_data[state] = calculate_rolling_features(weather_data[state])\n",
    "    print(f\"✓ {state}: {len(weather_data[state])} days processed\")\n",
    "\n",
    "print(\"\\nRolling features calculated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview rolling features\n",
    "print(\"Rolling features for Tasmania (last 10 days):\")\n",
    "cols_to_show = ['date', 'precipitation', 'rainfall_7d', 'rainfall_30d', \n",
    "                'temp_mean', 'temp_mean_7d', 'et0_7d', 'days_since_rain']\n",
    "weather_data['Tas'][cols_to_show].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Combine all weather data\nall_weather = pd.concat(weather_data.values(), ignore_index=True)\n\n# Check what columns we actually have\nprint(\"Available columns in weather data:\")\nprint(all_weather.columns.tolist())\nprint(f\"\\nTotal columns: {len(all_weather.columns)}\")\n\n# Select features that exist in the data\navailable_features = [\n    'date', 'state',\n    # Rolling rainfall\n    'rainfall_7d', 'rainfall_30d',\n    # Rolling temperature\n    'temp_max_7d', 'temp_min_7d', 'temp_range_7d',\n    # Evapotranspiration\n    'et0_7d', 'et0_30d',\n    # Water balance\n    'water_balance_7d', 'water_balance_30d',\n    # Days since rain\n    'days_since_rain',\n    # Astronomical (if available)\n    'daylength', 'season'\n]\n\n# Only include features that exist\nweather_features = ['date', 'state']\nfor feat in available_features[2:]:\n    if feat in all_weather.columns:\n        weather_features.append(feat)\n    else:\n        print(f\"⚠ Feature '{feat}' not found, skipping\")\n\n# Add anomalies if they exist\nif 'rain_anomaly' in all_weather.columns:\n    weather_features.extend(['rain_anomaly', 'temp_anomaly', 'et0_anomaly'])\nelse:\n    print(\"⚠ Anomaly features not calculated (climatology missing), skipping\")\n\nweather_for_merge = all_weather[weather_features].copy()\nweather_for_merge.columns = ['Sampling_Date', 'State'] + weather_features[2:]\n\nprint(f\"\\nWeather features prepared: {len(weather_features) - 2} features\")\nprint(f\"Features: {weather_features[2:]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch long-term climatology (1991-2020)\n",
    "print(\"Fetching climatology data for anomaly calculations...\\n\")\n",
    "\n",
    "climatology_data = {}\n",
    "for state in weather_data.keys():\n",
    "    print(f\"{state}:\")\n",
    "    clima = weather_client.fetch_climatology(state, start_year=1991, end_year=2020)\n",
    "    climatology_data[state] = clima\n",
    "    print(f\"  ✓ Climatology loaded\\n\")\n",
    "\n",
    "print(\"Climatology data ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview climatology\n",
    "print(\"Climatology for Tasmania (sample):\")\n",
    "climatology_data['Tas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# List all new features that were actually added\nnew_features = [col for col in train_enriched.columns if col not in train_wide.columns]\n\nprint(f\"Total new features: {len(new_features)}\")\nprint(f\"\\nNew features added:\")\nfor feat in new_features:\n    print(f\"  - {feat}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Feature summary:\")\nprint(\"=\"*60)\n\n# Get summary stats for numeric features only\nnumeric_new_features = [f for f in new_features if train_enriched[f].dtype in ['float64', 'int64']]\nif numeric_new_features:\n    print(train_enriched[numeric_new_features].describe().T)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate Daylength and Season Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_astronomical_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add daylength and season features.\n",
    "    \n",
    "    Args:\n",
    "        df: Weather dataframe with 'date' and 'lat' columns\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with daylength and season added\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate daylength for each row\n",
    "    df['daylength'] = df.apply(\n",
    "        lambda row: calculate_daylength(row['lat'], row['date']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Add season (Southern Hemisphere)\n",
    "    df['season'] = df['date'].apply(get_southern_hemisphere_season)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add astronomical features\n",
    "print(\"Calculating daylength and season...\\n\")\n",
    "for state in weather_data.keys():\n",
    "    weather_data[state] = add_astronomical_features(weather_data[state])\n",
    "    print(f\"✓ {state}: Astronomical features added\")\n",
    "\n",
    "print(\"\\nDaylength and season calculated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Merge Weather Features with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all weather data\n",
    "all_weather = pd.concat(weather_data.values(), ignore_index=True)\n",
    "\n",
    "# Select features to merge\n",
    "weather_features = [\n",
    "    'date', 'state',\n",
    "    # Rolling rainfall\n",
    "    'rainfall_7d', 'rainfall_30d',\n",
    "    # Rolling temperature\n",
    "    'temp_max_7d', 'temp_min_7d', 'temp_mean_7d', 'temp_mean_30d', 'temp_range_7d',\n",
    "    # Evapotranspiration\n",
    "    'et0_7d', 'et0_30d',\n",
    "    # Water balance\n",
    "    'water_balance_7d', 'water_balance_30d',\n",
    "    # Days since rain\n",
    "    'days_since_rain',\n",
    "    # Anomalies\n",
    "    'rain_anomaly', 'temp_anomaly', 'et0_anomaly',\n",
    "    # Astronomical\n",
    "    'daylength', 'season'\n",
    "]\n",
    "\n",
    "weather_for_merge = all_weather[weather_features].copy()\n",
    "weather_for_merge.columns = ['Sampling_Date', 'State'] + weather_features[2:]\n",
    "\n",
    "print(f\"Weather features prepared: {len(weather_features) - 2} features\")\n",
    "print(f\"Features: {weather_features[2:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with training data\n",
    "train_enriched = train_wide.merge(\n",
    "    weather_for_merge,\n",
    "    on=['Sampling_Date', 'State'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Original columns: {train_wide.shape[1]}\")\n",
    "print(f\"Enriched columns: {train_enriched.shape[1]}\")\n",
    "print(f\"New features added: {train_enriched.shape[1] - train_wide.shape[1]}\")\n",
    "print(f\"\\nRows with missing weather data: {train_enriched[weather_features[2:]].isnull().any(axis=1).sum()}\")\n",
    "\n",
    "train_enriched.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate NDVI Anomaly\n",
    "\n",
    "Compare each NDVI reading to the rolling mean for that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI statistics by state\n",
    "ndvi_stats = train_enriched.groupby('State')['Pre_GSHH_NDVI'].agg(['mean', 'std']).reset_index()\n",
    "ndvi_stats.columns = ['State', 'ndvi_mean_state', 'ndvi_std_state']\n",
    "\n",
    "# Merge and calculate anomaly\n",
    "train_enriched = train_enriched.merge(ndvi_stats, on='State', how='left')\n",
    "train_enriched['ndvi_anomaly'] = (\n",
    "    (train_enriched['Pre_GSHH_NDVI'] - train_enriched['ndvi_mean_state']) / \n",
    "    train_enriched['ndvi_std_state']\n",
    ")\n",
    "\n",
    "print(\"NDVI anomaly calculated\")\n",
    "print(\"\\nNDVI statistics by state:\")\n",
    "print(ndvi_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Summary and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all new features\n",
    "new_features = [\n",
    "    'rainfall_7d', 'rainfall_30d',\n",
    "    'temp_max_7d', 'temp_min_7d', 'temp_mean_7d', 'temp_mean_30d', 'temp_range_7d',\n",
    "    'et0_7d', 'et0_30d',\n",
    "    'water_balance_7d', 'water_balance_30d',\n",
    "    'days_since_rain',\n",
    "    'rain_anomaly', 'temp_anomaly', 'et0_anomaly',\n",
    "    'daylength', 'season', 'ndvi_anomaly'\n",
    "]\n",
    "\n",
    "print(f\"Total new features: {len(new_features)}\")\n",
    "print(\"\\nFeature summary:\")\n",
    "print(train_enriched[new_features].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations with target variables\n",
    "target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "# Select key weather features for correlation\n",
    "key_weather_features = [\n",
    "    'rainfall_7d', 'rainfall_30d', 'temp_mean_7d', 'et0_7d',\n",
    "    'water_balance_7d', 'days_since_rain', 'rain_anomaly',\n",
    "    'temp_anomaly', 'daylength', 'ndvi_anomaly'\n",
    "]\n",
    "\n",
    "# Calculate correlations\n",
    "corr_data = train_enriched[key_weather_features + target_cols].corr()\n",
    "target_corr = corr_data.loc[key_weather_features, target_cols]\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(target_corr, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Weather Feature Correlations with Biomass Targets')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 features correlated with Dry_Total_g:\")\n",
    "total_corr = target_corr['Dry_Total_g'].abs().sort_values(ascending=False)\n",
    "print(total_corr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize weather patterns by state\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Rainfall\n",
    "axes[0, 0].boxplot([train_enriched[train_enriched['State']==s]['rainfall_30d'].values \n",
    "                     for s in ['Tas', 'Vic', 'NSW', 'WA']],\n",
    "                    labels=['Tas', 'Vic', 'NSW', 'WA'])\n",
    "axes[0, 0].set_ylabel('30-day Rainfall (mm)')\n",
    "axes[0, 0].set_title('Rainfall by State')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Temperature\n",
    "axes[0, 1].boxplot([train_enriched[train_enriched['State']==s]['temp_mean_7d'].values \n",
    "                     for s in ['Tas', 'Vic', 'NSW', 'WA']],\n",
    "                    labels=['Tas', 'Vic', 'NSW', 'WA'])\n",
    "axes[0, 1].set_ylabel('7-day Mean Temp (°C)')\n",
    "axes[0, 1].set_title('Temperature by State')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Daylength\n",
    "for state in ['Tas', 'Vic', 'NSW', 'WA']:\n",
    "    state_data = train_enriched[train_enriched['State']==state].sort_values('Sampling_Date')\n",
    "    axes[1, 0].plot(state_data['Sampling_Date'], state_data['daylength'], \n",
    "                    marker='o', label=state, alpha=0.7)\n",
    "axes[1, 0].set_ylabel('Daylength (hours)')\n",
    "axes[1, 0].set_title('Daylength Over Time')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Water balance\n",
    "axes[1, 1].boxplot([train_enriched[train_enriched['State']==s]['water_balance_7d'].values \n",
    "                     for s in ['Tas', 'Vic', 'NSW', 'WA']],\n",
    "                    labels=['Tas', 'Vic', 'NSW', 'WA'])\n",
    "axes[1, 1].set_ylabel('7-day Water Balance (mm)')\n",
    "axes[1, 1].set_title('Water Balance by State')\n",
    "axes[1, 1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Enriched Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save enriched training data\n",
    "output_file = 'competition/train_enriched.csv'\n",
    "train_enriched.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✓ Enriched dataset saved to {output_file}\")\n",
    "print(f\"\\nDataset shape: {train_enriched.shape}\")\n",
    "print(f\"Total features: {train_enriched.shape[1]}\")\n",
    "print(f\"Weather features added: {len(new_features)}\")\n",
    "\n",
    "# Save feature list for reference\n",
    "feature_info = pd.DataFrame({\n",
    "    'feature': new_features,\n",
    "    'description': [\n",
    "        '7-day total rainfall (mm)',\n",
    "        '30-day total rainfall (mm)',\n",
    "        '7-day avg max temperature (°C)',\n",
    "        '7-day avg min temperature (°C)',\n",
    "        '7-day avg mean temperature (°C)',\n",
    "        '30-day avg mean temperature (°C)',\n",
    "        '7-day avg daily temperature range (°C)',\n",
    "        '7-day total evapotranspiration (mm)',\n",
    "        '30-day total evapotranspiration (mm)',\n",
    "        '7-day water balance: rain - ET (mm)',\n",
    "        '30-day water balance: rain - ET (mm)',\n",
    "        'Days since last >5mm rainfall',\n",
    "        'Rainfall anomaly (% from long-term mean)',\n",
    "        'Temperature anomaly (°C from long-term mean)',\n",
    "        'ET anomaly (% from long-term mean)',\n",
    "        'Hours of daylight',\n",
    "        'Season (0=Summer, 1=Autumn, 2=Winter, 3=Spring)',\n",
    "        'NDVI standardized anomaly (z-score)'\n",
    "    ]\n",
    "})\n",
    "\n",
    "feature_info.to_csv('weather_features_info.csv', index=False)\n",
    "print(\"\\n✓ Feature documentation saved to weather_features_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Weather Features Added:\n",
    "\n",
    "**Rainfall (3 features)**:\n",
    "- 7-day and 30-day totals\n",
    "- Rainfall anomaly (% from climatology)\n",
    "\n",
    "**Temperature (5 features)**:\n",
    "- 7-day avg max, min, mean\n",
    "- 30-day avg mean\n",
    "- 7-day avg daily range\n",
    "- Temperature anomaly\n",
    "\n",
    "**Evapotranspiration (3 features)**:\n",
    "- 7-day and 30-day totals\n",
    "- ET anomaly\n",
    "\n",
    "**Water Balance (2 features)**:\n",
    "- 7-day and 30-day (rainfall - ET)\n",
    "\n",
    "**Drought Indicator (1 feature)**:\n",
    "- Days since last significant rain\n",
    "\n",
    "**Astronomical (2 features)**:\n",
    "- Daylength (hours)\n",
    "- Season (0-3)\n",
    "\n",
    "**NDVI (1 feature)**:\n",
    "- NDVI anomaly (z-score)\n",
    "\n",
    "**Total: 18 new features**\n",
    "\n",
    "### Expected Impact:\n",
    "Weather features should significantly improve model performance, especially for:\n",
    "- **Dry_Total_g**: Highly correlated with recent rainfall and water balance\n",
    "- **Dry_Green_g**: Related to growing conditions (temp, water, daylength)\n",
    "- **GDM_g**: Active growth depends on favorable weather\n",
    "\n",
    "### Next Steps:\n",
    "1. Update multimodal model to use these new features\n",
    "2. Retrain and evaluate performance improvement\n",
    "3. Feature importance analysis\n",
    "4. Handle test data (will need to fetch weather for test dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}