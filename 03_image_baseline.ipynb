{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-Based Baseline Model\n",
    "\n",
    "Using transfer learning with ResNet50 to predict biomass directly from images.\n",
    "\n",
    "**Why images only?** The test set only provides images - no NDVI, Height, State, or Species data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('competition/train.csv')\n",
    "\n",
    "# Convert to wide format (one row per image)\n",
    "train_wide = train_df.pivot_table(\n",
    "    index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "    columns='target_name',\n",
    "    values='target'\n",
    ").reset_index()\n",
    "\n",
    "print(f\"Total images: {len(train_wide)}\")\n",
    "print(f\"Target columns: {['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']}\")\n",
    "train_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target columns\n",
    "target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "# Split into train and validation\n",
    "train_data, val_data = train_test_split(train_wide, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training images: {len(train_data)}\")\n",
    "print(f\"Validation images: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PastureDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir='competition', transform=None, target_cols=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: DataFrame with image_path and target columns\n",
    "            root_dir: Directory containing the images\n",
    "            transform: Optional transforms to apply to images\n",
    "            target_cols: List of target column names\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_cols = target_cols\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path\n",
    "        img_path = os.path.join(self.root_dir, self.dataframe.loc[idx, 'image_path'])\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get targets\n",
    "        targets = self.dataframe.loc[idx, self.target_cols].values.astype('float32')\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "        \n",
    "        return image, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define image transforms\n# Using ImageNet normalization since we're using pre-trained ResNet\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # ResNet expects 224x224\n    transforms.RandomHorizontalFlip(),  # Simple augmentation\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create datasets\ntrain_dataset = PastureDataset(train_data, transform=train_transform, target_cols=target_cols)\nval_dataset = PastureDataset(val_data, transform=val_transform, target_cols=target_cols)\n\n# Create dataloaders\nbatch_size = 16\n# Note: num_workers=0 to avoid multiprocessing issues in Jupyter notebooks\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Validation batches: {len(val_loader)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dataloader - visualize a batch\n",
    "sample_images, sample_targets = next(iter(train_loader))\n",
    "print(f\"Image batch shape: {sample_images.shape}\")  # [batch_size, 3, 224, 224]\n",
    "print(f\"Target batch shape: {sample_targets.shape}\")  # [batch_size, 5]\n",
    "print(f\"\\nSample targets (first image):\")\n",
    "for i, col in enumerate(target_cols):\n",
    "    print(f\"  {col}: {sample_targets[0, i]:.2f}g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Model with Pre-trained ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassPredictor(nn.Module):\n",
    "    def __init__(self, num_outputs=5, pretrained=True):\n",
    "        super(BiomassPredictor, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Get the number of features from ResNet's final layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        # ResNet outputs 1000 classes by default, we need 5 continuous outputs\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_outputs)  # 5 outputs for our 5 targets\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Create model\n",
    "model = BiomassPredictor(num_outputs=5, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model created!\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function - Mean Squared Error for regression\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer - Adam with learning rate\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler - reduce LR when validation loss plateaus\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Loss function: MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, targets in tqdm(loader, desc='Training'):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc='Validation'):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            all_predictions.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "    \n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    \n",
    "    return total_loss / len(loader.dataset), all_predictions, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training loop\nnum_epochs = 3  # Start with 3 epochs for quick baseline\nbest_val_loss = float('inf')\ntrain_losses = []\nval_losses = []\n\nprint(f\"Training for {num_epochs} epochs...\\n\")\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    # Train\n    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n    train_losses.append(train_loss)\n    \n    # Validate\n    val_loss, val_predictions, val_targets = validate_epoch(model, val_loader, criterion, device)\n    val_losses.append(val_loss)\n    \n    # Update learning rate\n    scheduler.step(val_loss)\n    \n    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n    \n    # Save best model\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'best_model.pth')\n        print(f\"✓ Saved best model (val_loss: {val_loss:.4f})\")\n    \n    print(\"-\" * 60)\n\nprint(\"\\nTraining complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(val_losses, label='Validation Loss', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Loaded best model\")\n",
    "\n",
    "# Get predictions on validation set\n",
    "val_loss, val_predictions, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"\\nBest validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R² scores and competition metric\n",
    "def calculate_competition_score(y_true, y_pred, target_cols):\n",
    "    \"\"\"\n",
    "    Calculate weighted R² score as per competition rules\n",
    "    \"\"\"\n",
    "    weights = {\n",
    "        'Dry_Green_g': 0.1,\n",
    "        'Dry_Dead_g': 0.1,\n",
    "        'Dry_Clover_g': 0.1,\n",
    "        'GDM_g': 0.2,\n",
    "        'Dry_Total_g': 0.5\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VALIDATION PERFORMANCE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    r2_scores = {}\n",
    "    total_score = 0\n",
    "    \n",
    "    for i, col in enumerate(target_cols):\n",
    "        r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        r2_scores[col] = r2\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  R² Score: {r2:.4f} (weight: {weights[col]})\")\n",
    "        print(f\"  MAE: {mae:.2f}g\")\n",
    "        print(f\"  Weighted contribution: {weights[col] * r2:.4f}\")\n",
    "        \n",
    "        total_score += weights[col] * r2\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"COMPETITION SCORE (Weighted R²): {total_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return r2_scores, total_score\n",
    "\n",
    "r2_scores, competition_score = calculate_competition_score(val_targets, val_predictions, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actuals\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(target_cols):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(val_targets[:, idx], val_predictions[:, idx], alpha=0.5)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(val_targets[:, idx].min(), val_predictions[:, idx].min())\n",
    "    max_val = max(val_targets[:, idx].max(), val_predictions[:, idx].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect')\n",
    "    \n",
    "    ax.set_xlabel(f'Actual {col}')\n",
    "    ax.set_ylabel(f'Predicted {col}')\n",
    "    ax.set_title(f'{col}\\nR² = {r2_scores[col]:.3f}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if predictions respect mathematical relationships\n",
    "pred_df = pd.DataFrame(val_predictions, columns=target_cols)\n",
    "\n",
    "# Total should equal Green + Dead + Clover\n",
    "pred_df['calc_total'] = pred_df['Dry_Green_g'] + pred_df['Dry_Dead_g'] + pred_df['Dry_Clover_g']\n",
    "pred_df['total_diff'] = pred_df['Dry_Total_g'] - pred_df['calc_total']\n",
    "\n",
    "# GDM should equal Green + Clover\n",
    "pred_df['calc_gdm'] = pred_df['Dry_Green_g'] + pred_df['Dry_Clover_g']\n",
    "pred_df['gdm_diff'] = pred_df['GDM_g'] - pred_df['calc_gdm']\n",
    "\n",
    "print(\"Prediction Consistency:\")\n",
    "print(f\"\\nDry_Total_g vs sum of components:\")\n",
    "print(f\"  Mean difference: {pred_df['total_diff'].mean():.2f}g\")\n",
    "print(f\"  Std difference: {pred_df['total_diff'].std():.2f}g\")\n",
    "print(f\"  Max absolute difference: {pred_df['total_diff'].abs().max():.2f}g\")\n",
    "\n",
    "print(f\"\\nGDM_g vs (Green + Clover):\")\n",
    "print(f\"  Mean difference: {pred_df['gdm_diff'].mean():.2f}g\")\n",
    "print(f\"  Std difference: {pred_df['gdm_diff'].std():.2f}g\")\n",
    "print(f\"  Max absolute difference: {pred_df['gdm_diff'].abs().max():.2f}g\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(pred_df['total_diff'], bins=30, edgecolor='black')\n",
    "axes[0].set_xlabel('Dry_Total_g - (Green + Dead + Clover)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Total Biomass Consistency')\n",
    "axes[0].axvline(0, color='red', linestyle='--', label='Perfect')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(pred_df['gdm_diff'], bins=30, edgecolor='black')\n",
    "axes[1].set_xlabel('GDM_g - (Green + Clover)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('GDM Consistency')\n",
    "axes[1].axvline(0, color='red', linestyle='--', label='Perfect')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Test Predictions\n",
    "\n",
    "Create submission file for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv('competition/test.csv')\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Unique test images: {test_df['image_path'].nunique()}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create test dataset (without targets)\nclass TestPastureDataset(Dataset):\n    def __init__(self, image_paths, root_dir='competition', transform=None):\n        self.image_paths = image_paths\n        self.root_dir = root_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root_dir, self.image_paths[idx])\n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image\n\n# Get unique test images\ntest_images = test_df['image_path'].unique()\nprint(f\"Predicting on {len(test_images)} test images\")\n\n# Create dataset and loader\ntest_dataset = TestPastureDataset(test_images, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader, desc='Predicting on test set'):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        test_predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "test_predictions = np.vstack(test_predictions)\n",
    "print(f\"\\nTest predictions shape: {test_predictions.shape}\")\n",
    "print(f\"Expected: ({len(test_images)}, 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "# Map predictions back to the required format\n",
    "pred_dict = {}\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    for col_idx, col in enumerate(target_cols):\n",
    "        pred_dict[img_path + '__' + col] = test_predictions[idx, col_idx]\n",
    "\n",
    "# Create submission\n",
    "submission = test_df.copy()\n",
    "submission['target'] = submission.apply(\n",
    "    lambda row: pred_dict.get(row['image_path'] + '__' + row['target_name'], 0.0),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Ensure no negative predictions\n",
    "submission['target'] = submission['target'].clip(lower=0)\n",
    "\n",
    "# Save\n",
    "submission[['sample_id', 'target']].to_csv('submission_image_baseline.csv', index=False)\n",
    "print(\"\\nSubmission saved to submission_image_baseline.csv\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(submission[['sample_id', 'target']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Image-Based Baseline Results:\n",
    "\n",
    "**Model:** ResNet50 (pre-trained on ImageNet) with custom regression head\n",
    "\n",
    "**Key Points:**\n",
    "- Uses ONLY images (no tabular features) since test set only provides images\n",
    "- Transfer learning from ImageNet helps with limited training data (357 images)\n",
    "- Simple data augmentation (flips, rotation, color jitter)\n",
    "- Predicts all 5 targets simultaneously\n",
    "\n",
    "**Check the results above:**\n",
    "- What's your validation competition score?\n",
    "- Which targets are harder to predict from images alone?\n",
    "- Are predictions mathematically consistent?\n",
    "\n",
    "### Potential Improvements:\n",
    "1. **Better architecture** - Try EfficientNet, Vision Transformer\n",
    "2. **More augmentation** - More aggressive transforms\n",
    "3. **Enforce consistency** - Post-process to ensure Total = sum of components\n",
    "4. **Ensemble** - Train multiple models and average\n",
    "5. **Larger input size** - 224x224 might lose detail, try 384x384\n",
    "6. **Fine-tune earlier layers** - Unfreeze more of ResNet\n",
    "7. **Better loss function** - Weight Dry_Total_g more heavily in loss\n",
    "8. **Cross-validation** - More robust evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}