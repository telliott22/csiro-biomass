{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4b: Auxiliary Pretrained Baseline\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Model 4b** is our current best-performing model with **R²=+0.6852 validation, R²=+0.51 Kaggle**.\n",
    "\n",
    "This notebook serves as a clean baseline to understand Model 4b's architecture and identify improvements.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Model 4b Performs Well\n",
    "\n",
    "Model 4b uses a **two-phase training approach**:\n",
    "\n",
    "### Phase 1: Auxiliary Pretraining (15 epochs)\n",
    "- Train CNN to predict **tabular features** from images:\n",
    "  - NDVI (vegetation greenness)\n",
    "  - Height (plant height in cm)\n",
    "  - Weather (14 features: rainfall, temp, ET0, etc.)\n",
    "  - State (4 classes: NSW, Tas, Vic, WA)\n",
    "  - Species (15 classes)\n",
    "\n",
    "**Why this works:**\n",
    "- Forces model to learn visual patterns that correlate with environment\n",
    "- Model achieves **82% state accuracy** - it can \"see\" location from image!\n",
    "- Creates rich image representations that encode environmental context\n",
    "\n",
    "### Phase 2: Biomass Fine-tuning (30 epochs)\n",
    "- Fine-tune pretrained CNN for biomass prediction\n",
    "- Uses **differential learning rates**:\n",
    "  - Backbone (pretrained): 1e-5 (small, preserve learned features)\n",
    "  - Biomass head (new): 3e-4 (larger, learn biomass patterns)\n",
    "\n",
    "**At inference:** Only needs images (no tabular features!) ✅ Kaggle-compatible\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Details\n",
    "\n",
    "```\n",
    "Input: 224×224 RGB Image\n",
    "         ↓\n",
    "   ResNet18 Backbone (pretrained on ImageNet)\n",
    "         ↓\n",
    "   512-dim features\n",
    "         ↓\n",
    "┌─────────────────────────────┐\n",
    "│  Phase 1: Auxiliary Heads   │\n",
    "│  - NDVI head (1 output)     │\n",
    "│  - Height head (1 output)   │\n",
    "│  - Weather head (14 outputs)│\n",
    "│  - State head (4 classes)   │\n",
    "│  - Species head (15 classes)│\n",
    "└─────────────────────────────┘\n",
    "         ↓\n",
    "┌─────────────────────────────┐\n",
    "│  Phase 2: Biomass Head      │\n",
    "│  512 → 256 → ReLU           │\n",
    "│        → Dropout(0.2)       │\n",
    "│        → 256 → 5 outputs    │\n",
    "└─────────────────────────────┘\n",
    "         ↓\n",
    "   5 biomass predictions\n",
    "```\n",
    "\n",
    "**Total parameters:** ~11.7M\n",
    "- ResNet18 backbone: ~11.2M\n",
    "- Auxiliary heads: ~150K\n",
    "- Biomass head: ~133K\n",
    "\n",
    "---\n",
    "\n",
    "## Current Performance\n",
    "\n",
    "**Validation (72 images):**\n",
    "- Overall R²: **+0.6852**\n",
    "- Per-target R²:\n",
    "  - Dry_Green_g: +0.6903\n",
    "  - Dry_Dead_g: +0.5243\n",
    "  - Dry_Clover_g: +0.5017\n",
    "  - GDM_g: +0.7254\n",
    "  - Dry_Total_g: +0.7243\n",
    "\n",
    "**Kaggle Test (unknown size):**\n",
    "- Overall R²: **+0.51**\n",
    "- Gap: **-0.175** (concerning - indicates overfitting or distribution shift)\n",
    "\n",
    "---\n",
    "\n",
    "## Known Issues & Improvement Opportunities\n",
    "\n",
    "### Issue 1: Large Validation-Test Gap (-0.175)\n",
    "**Possible causes:**\n",
    "1. **Overfitting** (most likely)\n",
    "   - Trained 30 epochs on small dataset (285 images)\n",
    "   - Validation R² bounced around (not monotonic)\n",
    "   - Best epoch was 29/30 (late in training)\n",
    "\n",
    "2. **Distribution shift**\n",
    "   - Test set may have different:\n",
    "     - Seasons, locations, species mix\n",
    "     - Image quality/lighting conditions\n",
    "   - Model 1 (simpler) scored worse (0.48), suggesting architecture is good\n",
    "\n",
    "3. **Validation split not representative**\n",
    "   - Random 80/20 split (not stratified)\n",
    "   - Only 72 validation images\n",
    "   - High variance in scores\n",
    "\n",
    "**Potential solutions:**\n",
    "- ✅ Early stopping (stop at epoch ~20-25)\n",
    "- ✅ Reduce Phase 2 epochs (30 → 20)\n",
    "- ✅ Stronger regularization (dropout 0.2 → 0.3-0.4)\n",
    "- ✅ Data augmentation (add more transforms)\n",
    "- ✅ Learning rate scheduling (reduce LR after plateaus)\n",
    "- ⚠️ Stratified split (hard with small dataset)\n",
    "- ⚠️ K-fold CV (too slow for iteration)\n",
    "\n",
    "### Issue 2: Target Normalization Uses Split Stats\n",
    "**Current:** Uses training split (285 images) statistics\n",
    "```python\n",
    "Dry_Green_g: mean=27.49g, std=26.19g\n",
    "```\n",
    "\n",
    "**Should use:** Full dataset (357 images) statistics\n",
    "```python\n",
    "Dry_Green_g: mean=26.624722g, std=25.401232g\n",
    "```\n",
    "\n",
    "**Impact:** Small but could contribute to test set mismatch\n",
    "\n",
    "### Issue 3: No Learning Rate Scheduling\n",
    "**Current:** Fixed LR throughout training\n",
    "- Phase 2 head: 3e-4 (all epochs)\n",
    "- Phase 2 backbone: 1e-5 (all epochs)\n",
    "\n",
    "**Potential improvement:** Reduce LR on plateau\n",
    "- Could help fine-tune without overfitting\n",
    "- Standard practice in deep learning\n",
    "\n",
    "### Issue 4: Limited Data Augmentation\n",
    "**Current augmentations:**\n",
    "- Random horizontal flip\n",
    "- Random vertical flip\n",
    "- Random rotation (10°)\n",
    "\n",
    "**Could add:**\n",
    "- Color jitter (brightness, contrast, saturation)\n",
    "- Random crop + resize\n",
    "- Gaussian blur\n",
    "- Random erasing\n",
    "\n",
    "**Caution:** Too much augmentation could hurt (Model 2 with ColorJitter scored worse)\n",
    "\n",
    "---\n",
    "\n",
    "## Recommended Next Steps\n",
    "\n",
    "### Priority 1: Reduce Overfitting (Most Important!)\n",
    "1. **Reduce Phase 2 epochs**: 30 → 20-25\n",
    "2. **Add learning rate scheduling**: ReduceLROnPlateau\n",
    "3. **Increase dropout**: 0.2 → 0.3-0.4\n",
    "4. **Use full dataset normalization stats**\n",
    "\n",
    "**Expected impact:** Close validation-test gap by ~0.05-0.10\n",
    "\n",
    "### Priority 2: Better Training Monitoring\n",
    "1. **Track validation R² every epoch** (not just loss)\n",
    "2. **Save checkpoints at multiple epochs** (not just best)\n",
    "3. **Plot learning curves** to identify overfitting visually\n",
    "\n",
    "### Priority 3: Ensemble Models\n",
    "1. **Train 3-5 models with different:**\n",
    "   - Random seeds\n",
    "   - Train/val splits\n",
    "   - Augmentation strategies\n",
    "2. **Average predictions** (simple ensemble)\n",
    "\n",
    "**Expected impact:** +0.02-0.05 R² improvement\n",
    "\n",
    "---\n",
    "\n",
    "## Training Configuration (Current Baseline)\n",
    "\n",
    "```python\n",
    "# Phase 1: Auxiliary Pretraining\n",
    "PHASE1_EPOCHS = 15\n",
    "PHASE1_LR = 3e-4\n",
    "PHASE1_WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Phase 2: Biomass Fine-tuning\n",
    "PHASE2_EPOCHS = 30  # ⚠️ Too many? Try 20-25\n",
    "PHASE2_HEAD_LR = 3e-4\n",
    "PHASE2_BACKBONE_LR = 1e-5\n",
    "PHASE2_WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Architecture\n",
    "HIDDEN_DIM = 256\n",
    "DROPOUT = 0.2  # ⚠️ Too low? Try 0.3-0.4\n",
    "\n",
    "# Data\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_VAL_SPLIT = 0.8  # 285 train, 72 val\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# Augmentation\n",
    "AUGMENT_HFLIP = True\n",
    "AUGMENT_VFLIP = True\n",
    "AUGMENT_ROTATE = 10  # degrees\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation\n",
    "\n",
    "Below is the complete implementation of Model 4b for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class AuxiliaryPretrainedModel(nn.Module):\n",
    "    \"\"\"Model 4b: Two-phase training with auxiliary tasks.\n",
    "    \n",
    "    Phase 1: Train to predict tabular features from images\n",
    "    Phase 2: Fine-tune for biomass prediction\n",
    "    \n",
    "    At inference: Only needs image (learned implicit tabular patterns)\n",
    "    \n",
    "    Args:\n",
    "        num_outputs: Number of biomass targets (5)\n",
    "        hidden_dim: Hidden layer size in biomass head (256 or 512)\n",
    "        dropout: Dropout rate in biomass head (0.2-0.4)\n",
    "        num_states: Number of state classes (4: NSW, Tas, Vic, WA)\n",
    "        num_species: Number of species classes (15)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_outputs=5, hidden_dim=256, dropout=0.2, \n",
    "                 num_states=4, num_species=15):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Shared backbone: ResNet18 (pretrained on ImageNet)\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        # Remove final FC layer, keep global avg pool\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])\n",
    "        # Output: 512-dim features\n",
    "        \n",
    "        # Phase 1: Auxiliary heads (predict tabular features from image)\n",
    "        self.ndvi_head = nn.Linear(512, 1)           # Predict NDVI\n",
    "        self.height_head = nn.Linear(512, 1)         # Predict height\n",
    "        self.weather_head = nn.Linear(512, 14)       # Predict 14 weather features\n",
    "        self.state_head = nn.Linear(512, num_states)     # Predict state (4 classes)\n",
    "        self.species_head = nn.Linear(512, num_species)  # Predict species (15 classes)\n",
    "        \n",
    "        # Phase 2: Biomass prediction head (used after pretraining)\n",
    "        self.biomass_head = nn.Sequential(\n",
    "            nn.Linear(512, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, mode='biomass'):\n",
    "        \"\"\"Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            x: Input image tensor [B, 3, 224, 224]\n",
    "            mode: 'auxiliary' (Phase 1) or 'biomass' (Phase 2)\n",
    "        \n",
    "        Returns:\n",
    "            If mode='auxiliary': dict with keys [ndvi, height, weather, state, species]\n",
    "            If mode='biomass': tensor [B, 5] with biomass predictions\n",
    "        \"\"\"\n",
    "        # Extract features from image\n",
    "        features = self.backbone(x)  # [B, 512, 1, 1]\n",
    "        features = features.flatten(1)  # [B, 512]\n",
    "        \n",
    "        if mode == 'auxiliary':\n",
    "            # Phase 1: Predict tabular features\n",
    "            return {\n",
    "                'ndvi': self.ndvi_head(features),\n",
    "                'height': self.height_head(features),\n",
    "                'weather': self.weather_head(features),\n",
    "                'state': self.state_head(features),\n",
    "                'species': self.species_head(features)\n",
    "            }\n",
    "        else:  # mode == 'biomass'\n",
    "            # Phase 2: Predict biomass\n",
    "            return self.biomass_head(features)\n",
    "\n",
    "# Example usage:\n",
    "# Phase 1: model(images, mode='auxiliary') → dict with tabular predictions\n",
    "# Phase 2: model(images, mode='biomass') → [B, 5] biomass predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights from Model 4b\n",
    "\n",
    "### What Works Well\n",
    "\n",
    "1. **Auxiliary pretraining is effective**\n",
    "   - 82% state accuracy shows model learns meaningful visual features\n",
    "   - Model can \"see\" location, season, plant type from image alone\n",
    "   - Validation R²=+0.6852 is very competitive\n",
    "\n",
    "2. **Differential learning rates help**\n",
    "   - Low LR (1e-5) for pretrained backbone preserves features\n",
    "   - Higher LR (3e-4) for new head allows learning biomass patterns\n",
    "\n",
    "3. **Architecture is appropriate for dataset size**\n",
    "   - ResNet18 (11.2M params) is reasonable for 285 training images\n",
    "   - Model 1 (simpler) scored worse, showing complexity is needed\n",
    "\n",
    "### What Needs Improvement\n",
    "\n",
    "1. **Overfitting is the main issue**\n",
    "   - 0.175 gap between validation and test is too large\n",
    "   - Model 1 (10 epochs) scored 0.48 vs Model 4b (30 epochs) 0.51\n",
    "   - Need: early stopping, more regularization\n",
    "\n",
    "2. **Training could be more stable**\n",
    "   - Validation R² bounces between epochs\n",
    "   - Need: learning rate scheduling, better monitoring\n",
    "\n",
    "3. **Small dataset is limiting**\n",
    "   - 285 training images is very small for deep learning\n",
    "   - Need: stronger augmentation, ensemble methods\n",
    "\n",
    "---\n",
    "\n",
    "## Next Experiment: Model 4b Improved\n",
    "\n",
    "Based on this analysis, the next notebook will implement:\n",
    "\n",
    "1. **Reduce Phase 2 epochs**: 30 → 20\n",
    "2. **Add LR scheduling**: ReduceLROnPlateau (factor=0.5, patience=3)\n",
    "3. **Increase dropout**: 0.2 → 0.3\n",
    "4. **Use full dataset normalization stats**\n",
    "5. **Better monitoring**: Track R² every epoch, save multiple checkpoints\n",
    "\n",
    "**Expected Kaggle score:** 0.55-0.58 (vs current 0.51)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
