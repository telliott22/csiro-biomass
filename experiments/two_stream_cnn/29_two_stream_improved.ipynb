{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Two-Stream CNN: RGB + Scalar NDVI\n",
    "\n",
    "## Solution to Performance Issue\n",
    "\n",
    "**Problem with v28:** NDVI \"image\" had no spatial variation ‚Üí CNN couldn't learn useful patterns  \n",
    "**Solution:** Use NDVI as scalar feature with MLP encoder instead of fake image\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "RGB Image (3√ó224√ó224)           NDVI Scalar (1)\n",
    "        ‚Üì                              ‚Üì\n",
    "    ResNet18                      MLP Encoder\n",
    "        ‚Üì                              ‚Üì\n",
    "   [512 features]               [128 features]\n",
    "        ‚Üì                              ‚Üì\n",
    "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Concatenate ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                      ‚Üì\n",
    "                Fusion MLP\n",
    "                      ‚Üì\n",
    "            [5 Biomass Targets]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(\"‚úì Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration\n",
    "\n",
    "# Model configuration\n",
    "CONFIG = {\n",
    "    # Architecture\n",
    "    'rgb_backbone': 'resnet18',\n",
    "    'ndvi_hidden': 128,  # NDVI encoder output dimension\n",
    "    'hidden_dim': 512,\n",
    "    'dropout': 0.3,\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 40,  # Increased since architecture is better\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 3e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'val_split': 0.2,\n",
    "    \n",
    "    # Data\n",
    "    'image_size': 224,\n",
    "    'augmentation': True,\n",
    "}\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = '../../competition/train_enriched.csv'\n",
    "IMAGE_BASE = '../../competition/'\n",
    "\n",
    "# Target columns\n",
    "TARGET_COLS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: RGB Stream (ResNet18) + NDVI Encoder (MLP)\")\n",
    "print(f\"  RGB features: 512\")\n",
    "print(f\"  NDVI features: {CONFIG['ndvi_hidden']}\")\n",
    "print(f\"  Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"  Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"\\n‚úì Configuration loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load & Prepare Data\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['Sampling_Date'] = pd.to_datetime(df['Sampling_Date'])\n",
    "df['full_image_path'] = df['image_path'].apply(lambda x: f\"{IMAGE_BASE}{x}\")\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "for col in TARGET_COLS:\n",
    "    print(f\"  {col:15s}: mean={df[col].mean():7.2f}g, std={df[col].std():7.2f}g\")\n",
    "\n",
    "print(f\"\\nNDVI statistics:\")\n",
    "print(f\"  Range: [{df['Pre_GSHH_NDVI'].min():.3f}, {df['Pre_GSHH_NDVI'].max():.3f}]\")\n",
    "print(f\"  Mean: {df['Pre_GSHH_NDVI'].mean():.3f}\")\n",
    "print(f\"  Std: {df['Pre_GSHH_NDVI'].std():.3f}\")\n",
    "\n",
    "# Train/val split\n",
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=CONFIG['val_split'], \n",
    "    random_state=42,\n",
    "    stratify=df['State']\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit:\")\n",
    "print(f\"  Training: {len(train_df)} images\")\n",
    "print(f\"  Validation: {len(val_df)} images\")\n",
    "\n",
    "# Calculate normalization statistics on TRAINING set\n",
    "target_means = torch.tensor([train_df[col].mean() for col in TARGET_COLS], dtype=torch.float32)\n",
    "target_stds = torch.tensor([train_df[col].std() for col in TARGET_COLS], dtype=torch.float32)\n",
    "\n",
    "ndvi_mean = train_df['Pre_GSHH_NDVI'].mean()\n",
    "ndvi_std = train_df['Pre_GSHH_NDVI'].std()\n",
    "\n",
    "print(f\"\\n‚úì Data loaded and split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Improved Dataset (NDVI as scalar)\n",
    "\n",
    "class ImprovedTwoStreamDataset(Dataset):\n",
    "    \"\"\"Dataset that returns RGB image and NDVI as SCALAR feature.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, target_means, target_stds, \n",
    "                 ndvi_mean, ndvi_std, augment=False):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.target_means = target_means\n",
    "        self.target_stds = target_stds\n",
    "        self.ndvi_mean = ndvi_mean\n",
    "        self.ndvi_std = ndvi_std\n",
    "        \n",
    "        # RGB transforms\n",
    "        rgb_transform_list = [transforms.Resize((CONFIG['image_size'], CONFIG['image_size']))]  \n",
    "        if augment:\n",
    "            rgb_transform_list.extend([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(10),\n",
    "            ])\n",
    "        rgb_transform_list.extend([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.rgb_transform = transforms.Compose(rgb_transform_list)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # 1. RGB image\n",
    "        rgb_img = Image.open(row['full_image_path']).convert('RGB')\n",
    "        rgb_img = self.rgb_transform(rgb_img)  # [3, 224, 224]\n",
    "        \n",
    "        # 2. NDVI as SCALAR (not fake image!)\n",
    "        ndvi_value = row['Pre_GSHH_NDVI']\n",
    "        ndvi_normalized = (ndvi_value - self.ndvi_mean) / self.ndvi_std\n",
    "        ndvi_scalar = torch.tensor([ndvi_normalized], dtype=torch.float32)  # [1]\n",
    "        \n",
    "        # 3. Targets\n",
    "        targets = torch.tensor(row[TARGET_COLS].values.astype('float32'), dtype=torch.float32)\n",
    "        targets_normalized = (targets - self.target_means) / self.target_stds\n",
    "        \n",
    "        return {\n",
    "            'rgb_image': rgb_img,\n",
    "            'ndvi_scalar': ndvi_scalar,  # KEY CHANGE: scalar not image\n",
    "            'targets': targets_normalized,\n",
    "            'targets_original': targets\n",
    "        }\n",
    "\n",
    "print(\"‚úì ImprovedTwoStreamDataset defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Improved Model Architecture\n",
    "\n",
    "class ImprovedTwoStreamModel(nn.Module):\n",
    "    \"\"\"RGB Stream (CNN) + NDVI Stream (MLP) ‚Üí Fusion ‚Üí Biomass Prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_outputs=5, ndvi_hidden=128, hidden_dim=512, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Stream 1: RGB (ResNet18 backbone)\n",
    "        resnet_rgb = models.resnet18(weights=None)\n",
    "        self.rgb_stream = nn.Sequential(*list(resnet_rgb.children())[:-1])\n",
    "        rgb_feature_dim = 512\n",
    "        \n",
    "        # Stream 2: NDVI (MLP encoder for scalar input)\n",
    "        self.ndvi_stream = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, ndvi_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Fusion layers\n",
    "        combined_dim = rgb_feature_dim + ndvi_hidden\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(combined_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, rgb_img, ndvi_scalar):\n",
    "        # Extract features from RGB stream\n",
    "        rgb_features = self.rgb_stream(rgb_img).flatten(1)  # [batch, 512]\n",
    "        \n",
    "        # Process NDVI through MLP\n",
    "        ndvi_features = self.ndvi_stream(ndvi_scalar)  # [batch, 128]\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined = torch.cat([rgb_features, ndvi_features], dim=1)  # [batch, 640]\n",
    "        \n",
    "        # Fusion and prediction\n",
    "        output = self.fusion(combined)  # [batch, 5]\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Create model\n",
    "model = ImprovedTwoStreamModel(\n",
    "    num_outputs=5,\n",
    "    ndvi_hidden=CONFIG['ndvi_hidden'],\n",
    "    hidden_dim=CONFIG['hidden_dim'],\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"‚úì ImprovedTwoStreamModel defined\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  RGB stream: {sum(p.numel() for p in model.rgb_stream.parameters()):,} params\")\n",
    "print(f\"  NDVI stream: {sum(p.numel() for p in model.ndvi_stream.parameters()):,} params\")\n",
    "print(f\"  Fusion layers: {sum(p.numel() for p in model.fusion.parameters()):,} params\")\n",
    "print(f\"\\nArchitecture:\")\n",
    "print(f\"  RGB ‚Üí 512 features\")\n",
    "print(f\"  NDVI ‚Üí {CONFIG['ndvi_hidden']} features\")\n",
    "print(f\"  Combined ‚Üí {512 + CONFIG['ndvi_hidden']} features ‚Üí Fusion ‚Üí 5 outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create Dataloaders\n",
    "\n",
    "train_dataset = ImprovedTwoStreamDataset(\n",
    "    train_df, target_means, target_stds, \n",
    "    ndvi_mean, ndvi_std, augment=CONFIG['augmentation']\n",
    ")\n",
    "\n",
    "val_dataset = ImprovedTwoStreamDataset(\n",
    "    val_df, target_means, target_stds,\n",
    "    ndvi_mean, ndvi_std, augment=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(\"‚úì Dataloaders created\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Test batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "print(f\"  RGB image: {sample_batch['rgb_image'].shape}\")\n",
    "print(f\"  NDVI scalar: {sample_batch['ndvi_scalar'].shape}  ‚Üê KEY CHANGE: scalar not image!\")\n",
    "print(f\"  Targets: {sample_batch['targets'].shape}\")\n",
    "\n",
    "# Verify NDVI values have variation\n",
    "print(f\"\\nNDVI batch statistics (normalized):\")\n",
    "print(f\"  Min: {sample_batch['ndvi_scalar'].min():.3f}\")\n",
    "print(f\"  Max: {sample_batch['ndvi_scalar'].max():.3f}\")\n",
    "print(f\"  Std: {sample_batch['ndvi_scalar'].std():.3f}\")\n",
    "print(f\"  ‚úì NDVI has variation across samples (unlike fake constant images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training Setup\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "print(\"‚úì Training setup complete\")\n",
    "print(f\"  Optimizer: AdamW\")\n",
    "print(f\"  Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  Weight decay: {CONFIG['weight_decay']}\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Training Functions\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(loader, desc='Training', leave=False):\n",
    "        rgb_imgs = batch['rgb_image'].to(device)\n",
    "        ndvi_scalars = batch['ndvi_scalar'].to(device)  # Changed: scalar not image\n",
    "        targets = batch['targets'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(rgb_imgs, ndvi_scalars)  # Changed signature\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * rgb_imgs.size(0)\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device, target_means, target_stds):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Validating', leave=False):\n",
    "            rgb_imgs = batch['rgb_image'].to(device)\n",
    "            ndvi_scalars = batch['ndvi_scalar'].to(device)  # Changed: scalar not image\n",
    "            targets = batch['targets'].to(device)\n",
    "            targets_original = batch['targets_original']\n",
    "            \n",
    "            outputs = model(rgb_imgs, ndvi_scalars)  # Changed signature\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Denormalize predictions\n",
    "            outputs_denorm = outputs.cpu() * target_stds + target_means\n",
    "            \n",
    "            total_loss += loss.item() * rgb_imgs.size(0)\n",
    "            all_preds.append(outputs_denorm.numpy())\n",
    "            all_targets.append(targets_original.numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    \n",
    "    # Calculate R¬≤ for each target\n",
    "    r2_scores = []\n",
    "    for i in range(5):\n",
    "        ss_res = np.sum((all_targets[:, i] - all_preds[:, i]) ** 2)\n",
    "        ss_tot = np.sum((all_targets[:, i] - np.mean(all_targets[:, i])) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
    "        r2_scores.append(r2)\n",
    "    \n",
    "    # Weighted R¬≤ (competition metric)\n",
    "    weights = np.array([0.1, 0.1, 0.1, 0.2, 0.5])\n",
    "    weighted_r2 = np.sum(np.array(r2_scores) * weights) / np.sum(weights)\n",
    "    \n",
    "    return total_loss / len(loader.dataset), weighted_r2, r2_scores\n",
    "\n",
    "print(\"‚úì Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Main Training Loop\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING TRAINING - IMPROVED TWO-STREAM MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Architecture: RGB (ResNet18) + NDVI (MLP) ‚Üí Fusion\")\n",
    "print(\"\\n\")\n",
    "\n",
    "best_val_r2 = -float('inf')\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_r2': []}\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    print(f\"Epoch {epoch+1}/{CONFIG['epochs']}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_r2, r2_scores = validate_epoch(\n",
    "        model, val_loader, criterion, device, target_means, target_stds\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Log\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_r2'].append(val_r2)\n",
    "    \n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"  Val R¬≤:     {val_r2:+.4f}\")\n",
    "    print(f\"  Per-target R¬≤: [{', '.join([f'{r:+.3f}' for r in r2_scores])}]\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_r2 > best_val_r2:\n",
    "        best_val_r2 = val_r2\n",
    "        torch.save(model.state_dict(), 'two_stream_improved_best.pth')\n",
    "        print(f\"  üíæ New best model saved! R¬≤={best_val_r2:+.4f}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best Val R¬≤: {best_val_r2:+.4f}\")\n",
    "print(f\"Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Plot Training History\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# R¬≤ plot\n",
    "axes[1].plot(history['val_r2'], label='Val R¬≤ (Improved)', marker='o', color='green')\n",
    "axes[1].axhline(y=0.51, color='red', linestyle='--', label='Baseline Kaggle (0.51)')\n",
    "axes[1].axhline(y=0.69, color='orange', linestyle='--', label='Baseline Val (0.69)')\n",
    "axes[1].axhline(y=0.327, color='purple', linestyle='--', label='Old Two-Stream (0.327)')\n",
    "axes[1].axhline(y=best_val_r2, color='blue', linestyle='--', label=f'Best ({best_val_r2:+.4f})')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('R¬≤ Score')\n",
    "axes[1].set_title('Validation R¬≤ Comparison')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_improved.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Training history plotted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Load Best Model & Final Evaluation\n",
    "\n",
    "print(\"Loading best model...\")\n",
    "model.load_state_dict(torch.load('two_stream_improved_best.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Final validation\n",
    "val_loss, val_r2, r2_scores = validate_epoch(\n",
    "    model, val_loader, criterion, device, target_means, target_stds\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL EVALUATION - IMPROVED TWO-STREAM MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"  Loss: {val_loss:.4f}\")\n",
    "print(f\"  Weighted R¬≤: {val_r2:+.4f}\")\n",
    "print(f\"\\nPer-target R¬≤:\")\n",
    "for i, col in enumerate(TARGET_COLS):\n",
    "    print(f\"  {col:15s}: {r2_scores[i]:+.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPARISON WITH ALL PREVIOUS ATTEMPTS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  Baseline (single ResNet18):        Val R¬≤ = ~0.69, Kaggle = 0.51\")\n",
    "print(f\"  K-Fold (all features):             Val R¬≤ = ~0.90, Kaggle = 0.50\")\n",
    "print(f\"  K-Fold (universal features):       Val R¬≤ = ~0.68, Kaggle = 0.40\")\n",
    "print(f\"  Two-Stream (fake NDVI image):      Val R¬≤ = +0.327 ‚ùå\")\n",
    "print(f\"  Two-Stream Improved (NDVI scalar): Val R¬≤ = {val_r2:+.4f} ‚Üê THIS MODEL\")\n",
    "\n",
    "# Performance assessment\n",
    "improvement_over_old = val_r2 - 0.327\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PERFORMANCE ASSESSMENT\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Improvement over old two-stream: {improvement_over_old:+.4f}\")\n",
    "\n",
    "if val_r2 >= 0.69:\n",
    "    print(f\"\\n‚úÖ EXCELLENT! Val R¬≤ ({val_r2:+.4f}) matches baseline validation\")\n",
    "    print(f\"   Expected Kaggle: 0.51-0.54\")\n",
    "    print(f\"   Recommendation: Create Kaggle submission!\")\n",
    "elif val_r2 >= 0.60:\n",
    "    print(f\"\\n‚úÖ GOOD! Val R¬≤ ({val_r2:+.4f}) is respectable\")\n",
    "    print(f\"   Expected Kaggle: 0.48-0.52\")\n",
    "    print(f\"   Recommendation: Worth submitting to Kaggle\")\n",
    "elif val_r2 >= 0.50:\n",
    "    print(f\"\\n‚ö†Ô∏è  MODERATE. Val R¬≤ ({val_r2:+.4f}) is decent\")\n",
    "    print(f\"   Expected Kaggle: 0.45-0.50\")\n",
    "    print(f\"   Recommendation: Try submission, but keep exploring\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå POOR. Val R¬≤ ({val_r2:+.4f}) is still low\")\n",
    "    print(f\"   Expected Kaggle: <0.45\")\n",
    "    print(f\"   Recommendation: Try different approach (add more features, different architecture)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Analysis: Why This Should Work Better\n",
    "\n",
    "### Problem with Old Architecture (v28)\n",
    "- NDVI \"image\" = constant value replicated 224√ó224 times\n",
    "- No spatial variation ‚Üí CNN filters learn nothing useful\n",
    "- Result: Val R¬≤ = 0.327 (terrible)\n",
    "\n",
    "### Solution in This Architecture (v29)\n",
    "- NDVI is treated as **scalar feature** (what it actually is!)\n",
    "- MLP encoder learns appropriate non-linear transformations\n",
    "- RGB stream still extracts spatial features from images\n",
    "- Fusion combines spatial (RGB) + scalar (NDVI) information\n",
    "\n",
    "### Expected Outcome\n",
    "- Should beat old two-stream (0.327) significantly\n",
    "- Should be competitive with baseline (~0.69 val)\n",
    "- Whether it beats baseline depends on whether NDVI encoder adds value beyond what RGB already captures\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### If Val R¬≤ ‚â• 0.65\n",
    "1. Create Kaggle submission notebook\n",
    "2. Upload checkpoint as dataset\n",
    "3. Submit to competition\n",
    "\n",
    "### If Val R¬≤ ‚âà 0.50-0.64\n",
    "1. Add more scalar features (Height, Season, Daylength)\n",
    "2. Try attention-based fusion instead of concatenation\n",
    "3. Try K-Fold ensemble of this architecture\n",
    "\n",
    "### If Val R¬≤ < 0.50\n",
    "1. Try ResNet50 instead of ResNet18 for RGB stream\n",
    "2. Add auxiliary pretraining (as in previous experiments)\n",
    "3. Consider that single-stream baseline is hard to beat\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
