{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Model with Fast.ai\n",
    "\n",
    "Combining images + tabular features using late fusion architecture.\n",
    "\n",
    "**Key Innovation**: Use auxiliary learning during training to predict NDVI/Height from images.\n",
    "This helps the model learn visual features that correlate with these metrics, even though they won't be available at test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Fast.ai imports\nfrom fastai.vision.all import *\nfrom fastai.tabular.all import *\nfrom fastai.callback.all import *\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\n\nsns.set_style('whitegrid')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Set seeds\nnp.random.seed(42)\ntorch.manual_seed(42)\nset_seed(42, reproducible=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('competition/train.csv')\n",
    "\n",
    "# Convert to wide format\n",
    "train_wide = train_df.pivot_table(\n",
    "    index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "    columns='target_name',\n",
    "    values='target'\n",
    ").reset_index()\n",
    "\n",
    "print(f\"Total images: {len(train_wide)}\")\n",
    "train_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target columns\n",
    "target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "# Add full image paths\n",
    "train_wide['full_image_path'] = train_wide['image_path'].apply(lambda x: f'competition/{x}')\n",
    "\n",
    "# Extract date features\n",
    "train_wide['Sampling_Date'] = pd.to_datetime(train_wide['Sampling_Date'])\n",
    "train_wide['Month'] = train_wide['Sampling_Date'].dt.month\n",
    "train_wide['DayOfYear'] = train_wide['Sampling_Date'].dt.dayofyear\n",
    "train_wide['Year'] = train_wide['Sampling_Date'].dt.year\n",
    "\n",
    "# Define tabular features\n",
    "tabular_features = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'Month', 'DayOfYear', 'State', 'Species']\n",
    "\n",
    "# Split train/validation\n",
    "train_data, val_data = train_test_split(train_wide, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"\\nTabular features: {tabular_features}\")\n",
    "print(f\"Target columns: {target_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Multimodal Dataset\n",
    "\n",
    "Custom dataset that loads both images and tabular features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalPastureDataset(Dataset):\n",
    "    def __init__(self, dataframe, tabular_features, target_cols, \n",
    "                 cat_features=['State', 'Species'], \n",
    "                 cont_features=['Pre_GSHH_NDVI', 'Height_Ave_cm', 'Month', 'DayOfYear'],\n",
    "                 image_size=224, augment=False):\n",
    "        \"\"\"\n",
    "        Dataset that combines images and tabular data\n",
    "        \"\"\"\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.tabular_features = tabular_features\n",
    "        self.target_cols = target_cols\n",
    "        self.cat_features = cat_features\n",
    "        self.cont_features = cont_features\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        self.cat_encoders = {}\n",
    "        for col in cat_features:\n",
    "            unique_vals = self.df[col].unique()\n",
    "            self.cat_encoders[col] = {val: i for i, val in enumerate(unique_vals)}\n",
    "        \n",
    "        # Scale continuous features\n",
    "        self.scaler = StandardScaler()\n",
    "        self.df[cont_features] = self.scaler.fit_transform(self.df[cont_features])\n",
    "        \n",
    "        # Image transforms\n",
    "        if augment:\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load and transform image\n",
    "        img_path = row['full_image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        # Get categorical features\n",
    "        cat_data = torch.tensor(\n",
    "            [self.cat_encoders[col][row[col]] for col in self.cat_features],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        # Get continuous features\n",
    "        cont_data = torch.tensor(\n",
    "            row[self.cont_features].values.astype('float32'),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        # Get targets\n",
    "        targets = torch.tensor(\n",
    "            row[self.target_cols].values.astype('float32'),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        # Also return NDVI and Height for auxiliary learning\n",
    "        # Note: These are the ORIGINAL unscaled values from before scaling\n",
    "        ndvi_height = torch.tensor(\n",
    "            [row['Pre_GSHH_NDVI'], row['Height_Ave_cm']],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        return image, cat_data, cont_data, targets, ndvi_height\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MultimodalPastureDataset(\n",
    "    train_data.copy(),\n",
    "    tabular_features,\n",
    "    target_cols,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_dataset = MultimodalPastureDataset(\n",
    "    val_data.copy(),\n",
    "    tabular_features,\n",
    "    target_cols,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dataset\n",
    "sample = train_dataset[0]\n",
    "image, cat_data, cont_data, targets, ndvi_height = sample\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Categorical data shape: {cat_data.shape}\")\n",
    "print(f\"Continuous data shape: {cont_data.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")\n",
    "print(f\"NDVI/Height shape: {ndvi_height.shape}\")\n",
    "print(f\"\\nTargets: {targets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Multimodal Model with Auxiliary Learning\n",
    "\n",
    "Architecture:\n",
    "- **Image branch**: ResNet50 → image features\n",
    "- **Tabular branch**: Embedding + Dense → tabular features  \n",
    "- **Fusion**: Concatenate both → Dense layers → predictions\n",
    "- **Auxiliary**: Image features → predict NDVI/Height (training only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalBiomassPredictor(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_cat_features=2,\n",
    "                 cat_embedding_sizes=[10, 20],  # State, Species\n",
    "                 num_cont_features=4,\n",
    "                 num_outputs=5,\n",
    "                 image_model='resnet50',\n",
    "                 use_auxiliary=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_auxiliary = use_auxiliary\n",
    "        \n",
    "        # ========== IMAGE BRANCH ==========\n",
    "        # Load pre-trained ResNet50\n",
    "        if image_model == 'resnet50':\n",
    "            self.image_encoder = models.resnet50(pretrained=True)\n",
    "            image_features = 2048\n",
    "        elif image_model == 'resnet34':\n",
    "            self.image_encoder = models.resnet34(pretrained=True)\n",
    "            image_features = 512\n",
    "        \n",
    "        # Remove the final FC layer\n",
    "        self.image_encoder = nn.Sequential(*list(self.image_encoder.children())[:-1])\n",
    "        \n",
    "        # ========== TABULAR BRANCH ==========\n",
    "        # Embeddings for categorical variables\n",
    "        self.cat_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(size, emb_size)\n",
    "            for size, emb_size in zip([len(train_dataset.cat_encoders[f]) for f in ['State', 'Species']], \n",
    "                                       cat_embedding_sizes)\n",
    "        ])\n",
    "        \n",
    "        # Total tabular features size\n",
    "        tabular_size = sum(cat_embedding_sizes) + num_cont_features\n",
    "        \n",
    "        # Tabular processing\n",
    "        self.tabular_encoder = nn.Sequential(\n",
    "            nn.Linear(tabular_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # ========== FUSION ==========\n",
    "        # Combine image + tabular features\n",
    "        combined_size = image_features + 32\n",
    "        \n",
    "        self.fusion_head = nn.Sequential(\n",
    "            nn.Linear(combined_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_outputs)\n",
    "        )\n",
    "        \n",
    "        # ========== AUXILIARY HEAD ==========\n",
    "        # Predict NDVI and Height from image features (training only)\n",
    "        if use_auxiliary:\n",
    "            self.auxiliary_head = nn.Sequential(\n",
    "                nn.Linear(image_features, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(128, 2)  # Predict [NDVI, Height]\n",
    "            )\n",
    "    \n",
    "    def forward(self, image, cat_data, cont_data, return_auxiliary=False):\n",
    "        # Image features\n",
    "        img_features = self.image_encoder(image)\n",
    "        img_features = img_features.view(img_features.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Tabular features\n",
    "        cat_embeddings = [emb(cat_data[:, i]) for i, emb in enumerate(self.cat_embeddings)]\n",
    "        cat_features = torch.cat(cat_embeddings, dim=1)\n",
    "        tabular_input = torch.cat([cat_features, cont_data], dim=1)\n",
    "        tab_features = self.tabular_encoder(tabular_input)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([img_features, tab_features], dim=1)\n",
    "        \n",
    "        # Main predictions\n",
    "        biomass_pred = self.fusion_head(combined)\n",
    "        \n",
    "        # Auxiliary predictions (NDVI, Height from image only)\n",
    "        if return_auxiliary and self.use_auxiliary:\n",
    "            aux_pred = self.auxiliary_head(img_features)\n",
    "            return biomass_pred, aux_pred\n",
    "        \n",
    "        return biomass_pred\n",
    "\n",
    "# Create model\n",
    "model = MultimodalBiomassPredictor(\n",
    "    num_cat_features=2,\n",
    "    cat_embedding_sizes=[5, 15],\n",
    "    num_cont_features=4,\n",
    "    num_outputs=5,\n",
    "    image_model='resnet50',\n",
    "    use_auxiliary=True\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Multimodal model created!\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Loss Function\n",
    "\n",
    "Combine:\n",
    "1. Main loss: Weighted MSE for biomass predictions (following competition weights)\n",
    "2. Auxiliary loss: MSE for NDVI/Height predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitionLoss(nn.Module):\n",
    "    def __init__(self, use_auxiliary=True, aux_weight=0.1):\n",
    "        super().__init__()\n",
    "        self.use_auxiliary = use_auxiliary\n",
    "        self.aux_weight = aux_weight\n",
    "        \n",
    "        # Competition weights for each target\n",
    "        self.target_weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]).to(device)\n",
    "        # Order: Dry_Green, Dry_Dead, Dry_Clover, GDM, Dry_Total\n",
    "        \n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self, biomass_pred, biomass_true, aux_pred=None, aux_true=None):\n",
    "        # Main biomass loss (weighted by competition metric)\n",
    "        biomass_mse = self.mse(biomass_pred, biomass_true)\n",
    "        weighted_biomass_loss = (biomass_mse * self.target_weights).mean()\n",
    "        \n",
    "        # Auxiliary loss (predict NDVI and Height)\n",
    "        if self.use_auxiliary and aux_pred is not None and aux_true is not None:\n",
    "            aux_loss = self.mse(aux_pred, aux_true).mean()\n",
    "            total_loss = weighted_biomass_loss + self.aux_weight * aux_loss\n",
    "            return total_loss, weighted_biomass_loss, aux_loss\n",
    "        \n",
    "        return weighted_biomass_loss, weighted_biomass_loss, torch.tensor(0.0).to(device)\n",
    "\n",
    "criterion = CompetitionLoss(use_auxiliary=True, aux_weight=0.1)\n",
    "print(\"Custom loss function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# Scheduler - One Cycle (fast.ai style)\n",
    "num_epochs = 10\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=steps_per_epoch\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: AdamW (lr={learning_rate})\")\n",
    "print(f\"Scheduler: OneCycleLR\")\n",
    "print(f\"Epochs: {num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    biomass_loss_sum = 0\n",
    "    aux_loss_sum = 0\n",
    "    \n",
    "    for images, cat_data, cont_data, targets, ndvi_height in loader:\n",
    "        images = images.to(device)\n",
    "        cat_data = cat_data.to(device)\n",
    "        cont_data = cont_data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        ndvi_height = ndvi_height.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with auxiliary output\n",
    "        biomass_pred, aux_pred = model(images, cat_data, cont_data, return_auxiliary=True)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss, biomass_loss, aux_loss = criterion(biomass_pred, targets, aux_pred, ndvi_height)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        biomass_loss_sum += biomass_loss.item() * images.size(0)\n",
    "        aux_loss_sum += aux_loss.item() * images.size(0)\n",
    "    \n",
    "    return (total_loss / len(loader.dataset), \n",
    "            biomass_loss_sum / len(loader.dataset),\n",
    "            aux_loss_sum / len(loader.dataset))\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, cat_data, cont_data, targets, ndvi_height in loader:\n",
    "            images = images.to(device)\n",
    "            cat_data = cat_data.to(device)\n",
    "            cont_data = cont_data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass (no auxiliary during validation)\n",
    "            biomass_pred = model(images, cat_data, cont_data, return_auxiliary=False)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss, _, _ = criterion(biomass_pred, targets)\n",
    "            \n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            all_preds.append(biomass_pred.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    \n",
    "    return total_loss / len(loader.dataset), all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "biomass_losses = []\n",
    "aux_losses = []\n",
    "\n",
    "print(f\"Training for {num_epochs} epochs...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, biomass_loss, aux_loss = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, scheduler, device\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    biomass_losses.append(biomass_loss)\n",
    "    aux_losses.append(aux_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_preds, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"  Train Loss: {train_loss:.4f} (Biomass: {biomass_loss:.4f}, Aux: {aux_loss:.4f})\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_multimodal_model.pth')\n",
    "        print(f\"  ✓ Saved best model\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(train_losses, label='Train Loss', marker='o')\n",
    "axes[0].plot(val_losses, label='Val Loss', marker='o')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Progress')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Component losses\n",
    "axes[1].plot(biomass_losses, label='Biomass Loss', marker='o')\n",
    "axes[1].plot(aux_losses, label='Auxiliary Loss', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Loss Components')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_multimodal_model.pth'))\n",
    "print(\"Loaded best model\\n\")\n",
    "\n",
    "# Get final validation predictions\n",
    "val_loss, val_preds, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "# Calculate competition score\n",
    "def calculate_competition_score(y_true, y_pred, target_cols):\n",
    "    weights = {\n",
    "        'Dry_Green_g': 0.1,\n",
    "        'Dry_Dead_g': 0.1,\n",
    "        'Dry_Clover_g': 0.1,\n",
    "        'GDM_g': 0.2,\n",
    "        'Dry_Total_g': 0.5\n",
    "    }\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"MULTIMODAL MODEL VALIDATION PERFORMANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    r2_scores = {}\n",
    "    total_score = 0\n",
    "    \n",
    "    for i, col in enumerate(target_cols):\n",
    "        r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        r2_scores[col] = r2\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  R² Score: {r2:.4f} (weight: {weights[col]})\")\n",
    "        print(f\"  MAE: {mae:.2f}g\")\n",
    "        print(f\"  Weighted contribution: {weights[col] * r2:.4f}\")\n",
    "        \n",
    "        total_score += weights[col] * r2\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"COMPETITION SCORE (Weighted R²): {total_score:.4f}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return r2_scores, total_score\n",
    "\n",
    "r2_scores, competition_score = calculate_competition_score(val_targets, val_preds, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(target_cols):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    ax.scatter(val_targets[:, idx], val_preds[:, idx], alpha=0.5)\n",
    "    \n",
    "    min_val = min(val_targets[:, idx].min(), val_preds[:, idx].min())\n",
    "    max_val = max(val_targets[:, idx].max(), val_preds[:, idx].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect')\n",
    "    \n",
    "    ax.set_xlabel(f'Actual {col}')\n",
    "    ax.set_ylabel(f'Predicted {col}')\n",
    "    ax.set_title(f'{col}\\nR² = {r2_scores[col]:.3f}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Image-Only Model for Test Predictions\n",
    "\n",
    "Since test data doesn't have tabular features, create a simplified version that uses only images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageOnlyPredictor(nn.Module):\n",
    "    \"\"\"Simplified model for test time - uses only images\"\"\"\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.image_encoder = base_model.image_encoder\n",
    "        \n",
    "        # Direct path from image features to predictions\n",
    "        image_features = 2048  # ResNet50\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(image_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 5)\n",
    "        )\n",
    "    \n",
    "    def forward(self, image):\n",
    "        img_features = self.image_encoder(image)\n",
    "        img_features = img_features.view(img_features.size(0), -1)\n",
    "        return self.head(img_features)\n",
    "\n",
    "# Create image-only model and copy weights\n",
    "image_only_model = ImageOnlyPredictor(model)\n",
    "image_only_model = image_only_model.to(device)\n",
    "\n",
    "print(\"Image-only model created for test predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv('competition/test.csv')\n",
    "test_images = test_df['image_path'].unique()\n",
    "\n",
    "print(f\"Test images: {len(test_images)}\")\n",
    "\n",
    "# Create simple test dataset (images only)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class SimpleTestDataset(Dataset):\n",
    "    def __init__(self, image_paths, root='competition', transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.root}/{self.image_paths[idx]}\"\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "test_dataset = SimpleTestDataset(test_images, transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "# Generate predictions\n",
    "image_only_model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = image_only_model(images)\n",
    "        test_predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "test_predictions = np.vstack(test_predictions)\n",
    "print(f\"\\nTest predictions shape: {test_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "pred_dict = {}\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    for col_idx, col in enumerate(target_cols):\n",
    "        pred_dict[img_path + '__' + col] = test_predictions[idx, col_idx]\n",
    "\n",
    "submission = test_df.copy()\n",
    "submission['target'] = submission.apply(\n",
    "    lambda row: pred_dict.get(row['image_path'] + '__' + row['target_name'], 0.0),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Clip negative predictions\n",
    "submission['target'] = submission['target'].clip(lower=0)\n",
    "\n",
    "# Save\n",
    "submission[['sample_id', 'target']].to_csv('submission_multimodal.csv', index=False)\n",
    "print(\"\\nSubmission saved to submission_multimodal.csv\")\n",
    "print(submission[['sample_id', 'target']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Multimodal Architecture:\n",
    "- **Image branch**: ResNet50 pre-trained features\n",
    "- **Tabular branch**: Embeddings + dense layers for NDVI, Height, State, Species, Date\n",
    "- **Late fusion**: Concatenate and predict biomass\n",
    "- **Auxiliary learning**: Model learns to predict NDVI/Height from images during training\n",
    "\n",
    "### Key Improvements:\n",
    "1. Uses ALL available data during training (images + tabular)\n",
    "2. Auxiliary task helps model learn relevant visual features\n",
    "3. Weighted loss function aligned with competition metric\n",
    "4. One-cycle learning rate schedule\n",
    "5. Better data augmentation\n",
    "\n",
    "### Performance:\n",
    "Check the validation R² scores and competition score above to see improvement over image-only baseline!\n",
    "\n",
    "### Next Steps:\n",
    "- Try different architectures (EfficientNet, Vision Transformer)\n",
    "- Experiment with auxiliary task weighting\n",
    "- Ensemble multiple models\n",
    "- Cross-validation for more robust evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}