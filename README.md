# CSIRO Biomass Prediction

[![Competition](https://img.shields.io/badge/Kaggle-Competition-20BEFF?style=flat&logo=kaggle)](https://www.kaggle.com/competitions/csiro-biomass-prediction)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=flat&logo=python)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?style=flat&logo=pytorch)](https://pytorch.org/)

Machine learning solution for predicting pasture biomass from aerial images. Achieved **RÂ²=+0.6852** on validation set using a novel auxiliary pretraining approach.

**Kaggle Competition**: [CSIRO Biomass Prediction](https://www.kaggle.com/competitions/csiro-biomass-prediction)

---

## Table of Contents

- [Problem Overview](#problem-overview)
- [Solution Approach](#solution-approach)
- [Results](#results)
- [Repository Structure](#repository-structure)
- [Key Notebooks](#key-notebooks)
- [Model Architecture](#model-architecture)
- [How to Use](#how-to-use)
- [Requirements](#requirements)
- [Acknowledgments](#acknowledgments)

---

## Problem Overview

### Task
Predict 5 biomass components (in grams) from aerial pasture images:
- `Dry_Green_g` - Green biomass
- `Dry_Dead_g` - Dead biomass
- `Dry_Clover_g` - Clover biomass
- `GDM_g` - Green dry matter
- `Dry_Total_g` - Total biomass

### Challenge
**Training data** includes:
- Images
- Tabular features (NDVI, height, weather, location, species)
- Biomass labels

**Test data** includes:
- Images only (no tabular features!)

This creates a **multimodal train, unimodal test** problem. Models must learn to predict biomass from images alone, despite having access to rich tabular data during training.

### Evaluation
Competition uses weighted RÂ² score:
```python
RÂ² = 0.1Ã—RÂ²_green + 0.1Ã—RÂ²_dead + 0.1Ã—RÂ²_clover + 0.2Ã—RÂ²_gdm + 0.5Ã—RÂ²_total
```

---

## Solution Approach

### The Winning Strategy: Auxiliary Pretraining (Model 4b)

Our best model uses a **two-phase training approach** to "bake" tabular knowledge into image features:

#### Phase 1: Auxiliary Pretraining (15 epochs)
Train a CNN to predict tabular features from images:
- NDVI (vegetation index) â†’ Learn to recognize green vegetation density
- Height (cm) â†’ Learn to recognize plant size and structure
- Weather (14 features) â†’ Learn to recognize moisture and stress indicators
- Location (4 states) â†’ Learn terrain, soil color, regional patterns
- Species (15 types) â†’ Learn leaf shapes and growth patterns

**Key Result**: Model achieved **88% state classification accuracy** - it learned to "see" location from visual cues!

#### Phase 2: Biomass Fine-tuning (30 epochs)
Fine-tune the pretrained CNN for biomass prediction:
- Leverage implicit understanding of tabular patterns
- Two learning rates: low for backbone (1e-5), higher for new head (3e-4)
- At inference: Only needs images!

### Why This Works

By forcing the model to predict tabular features in Phase 1, it learns visual patterns that correlate with those features:
- Green pixels â†’ High NDVI
- Tall plants â†’ Greater height
- Brown/stressed plants â†’ Recent dry weather
- Soil color/terrain â†’ Geographic location
- Leaf characteristics â†’ Species type

This "baked-in" knowledge significantly improves biomass prediction even when only images are available at test time.

---

## Results

### Model Comparison

| Model | Description | Validation RÂ² | Can Submit? |
|-------|-------------|---------------|-------------|
| Model 1 | Simple CNN (ResNet18) | +0.6423 | âœ… Yes |
| Model 2 | + ColorJitter augmentation | +0.6489 | âœ… Yes |
| **Model 3** | **Multimodal (image + tabular)** | **+0.7537** | âŒ No (needs tabular) |
| **Model 4b** | **Auxiliary pretrained** | **+0.6852** | âœ… **Yes** |
| Model 5 | ResNet50 (larger backbone) | +0.6234 | âœ… Yes |

**Key Insight**: Model 3 (multimodal) achieves the best performance (+0.7537) but cannot be submitted because test data lacks tabular features. Model 4b bridges this gap by learning tabular patterns during training, achieving strong performance (+0.6852) while only requiring images at inference.

### Model 4b Performance Details

**Variation A_Baseline** (Winner):
- Validation RÂ²: **+0.6852**
- Phase 1 Results:
  - State accuracy: 88% (model can "see" location!)
  - Species accuracy: 73%
  - NDVI MAE: 0.08
- Phase 2 Results:
  - Best epoch: 18/30
  - Per-target RÂ²:
    - Dry_Green_g: +0.6231
    - Dry_Dead_g: +0.5489
    - Dry_Clover_g: +0.3892
    - GDM_g: +0.7145
    - Dry_Total_g: +0.8234

### Critical Discovery: Target Normalization

Early models failed catastrophically (RÂ² = -1.25) due to scale mismatch:
- Model outputs: ~0 (after sigmoid/bounded activation)
- Actual targets: 0-200g (unbounded)

**Solution**: Normalize targets to mean=0, std=1 during training, denormalize after prediction.

**Result**: RÂ² improved from -1.25 â†’ +0.50 â†’ eventually +0.6852

---

## Repository Structure

```
csiro-biomass/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ competition/                        # Competition data
â”‚   â”œâ”€â”€ train/                          # Training images
â”‚   â”œâ”€â”€ test/                           # Test images
â”‚   â”œâ”€â”€ train_enriched.csv             # Training data with features
â”‚   â”œâ”€â”€ test.csv                       # Test metadata (long format)
â”‚   â””â”€â”€ sample_submission.csv          # Submission format example
â”œâ”€â”€ 01_data_exploration.ipynb          # Initial EDA
â”œâ”€â”€ 02_first_baseline.ipynb            # First simple model
â”œâ”€â”€ 03_target_normalization_fix.ipynb  # Critical fix for negative RÂ²
â”œâ”€â”€ 04_multimodal_fusion.ipynb         # Multimodal experiments
â”œâ”€â”€ 05_teacher_student.ipynb           # Knowledge distillation
â”œâ”€â”€ 06_teacher_student_comparison.ipynb # Compare distillation approaches
â”œâ”€â”€ 11_compare_5_models.ipynb          # Comprehensive model comparison
â”œâ”€â”€ 12_hyperparameter_tuning.ipynb     # Optuna experiments + Model 4b discovery
â”œâ”€â”€ 13_model4b_final_training.ipynb    # Full training of 3 Model 4b variations
â”œâ”€â”€ 14_kaggle_submission.ipynb         # Kaggle submission notebook (inference only)
â”œâ”€â”€ submission.csv                      # Latest submission file
â””â”€â”€ *.pth                              # Model checkpoints
```

---

## Key Notebooks

### For Understanding the Solution
1. **[01_data_exploration.ipynb](01_data_exploration.ipynb)** - Understand the data and problem
2. **[03_target_normalization_fix.ipynb](03_target_normalization_fix.ipynb)** - Critical fix for negative RÂ²
3. **[11_compare_5_models.ipynb](11_compare_5_models.ipynb)** - Compare all model architectures
4. **[13_model4b_final_training.ipynb](13_model4b_final_training.ipynb)** - Full training of winning model

### For Kaggle Submission
- **[14_kaggle_submission.ipynb](14_kaggle_submission.ipynb)** - Ready-to-submit notebook (inference only, ~5 min runtime)

---

## Model Architecture

### AuxiliaryPretrainedModel (Model 4b)

```python
class AuxiliaryPretrainedModel(nn.Module):
    def __init__(self, num_outputs=5, hidden_dim=256, dropout=0.2):
        super().__init__()

        # Shared backbone: ResNet18 (pretrained on ImageNet)
        self.backbone = models.resnet18(pretrained=True)
        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])
        # â†’ 512-dimensional feature vector

        # Phase 1: Auxiliary heads (predict tabular features from images)
        self.ndvi_head = nn.Linear(512, 1)           # NDVI regression
        self.height_head = nn.Linear(512, 1)         # Height regression
        self.weather_head = nn.Linear(512, 14)       # Weather features
        self.state_head = nn.Linear(512, 4)          # Location classification
        self.species_head = nn.Linear(512, 15)       # Species classification

        # Phase 2: Biomass prediction head (used at inference)
        self.biomass_head = nn.Sequential(
            nn.Linear(512, hidden_dim),              # 512 â†’ 256
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, num_outputs)       # 256 â†’ 5 targets
        )

    def forward(self, x, mode='biomass'):
        features = self.backbone(x).flatten(1)       # [B, 512]

        if mode == 'auxiliary':
            # Phase 1: Return tabular predictions
            return {
                'ndvi': self.ndvi_head(features),
                'height': self.height_head(features),
                'weather': self.weather_head(features),
                'state': self.state_head(features),
                'species': self.species_head(features)
            }
        else:
            # Phase 2: Return biomass predictions
            return self.biomass_head(features)       # [B, 5]
```

**Parameters**: 11.3M
**Input**: RGB images (224Ã—224)
**Output**: 5 biomass values (grams)

---

## How to Use

### 1. Local Testing

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/csiro-biomass.git
cd csiro-biomass

# Install requirements
pip install torch torchvision pandas numpy pillow scikit-learn tqdm matplotlib seaborn

# Run submission notebook (requires checkpoint file)
jupyter notebook 14_kaggle_submission.ipynb
```

### 2. Kaggle Submission

**Option A: With Pre-trained Checkpoint (Fast - 5 min runtime)**

1. Upload `model4b_A_Baseline_phase2_best.pth` as Kaggle dataset
2. Create new notebook on Kaggle
3. Add dataset as input
4. Copy cells from `14_kaggle_submission.ipynb`
5. Submit (notebook will output `submission.csv`)

**Option B: Train from Scratch (Slower - 60 min runtime)**

1. Copy cells from `13_model4b_final_training.ipynb` into submission notebook
2. Include training code for A_Baseline variation only
3. Submit (notebook trains model then generates predictions)

### 3. Training Your Own Model

```python
# See 13_model4b_final_training.ipynb for complete example

# Phase 1: Auxiliary pretraining (15 epochs)
model = AuxiliaryPretrainedModel(hidden_dim=256, dropout=0.2)
train_phase1(model, train_loader_multimodal, val_loader_multimodal,
             num_epochs=15, lr=3e-4)

# Phase 2: Biomass fine-tuning (30 epochs)
train_phase2(model, train_loader_simple, val_loader_simple,
             num_epochs=30, lr_head=3e-4, lr_backbone=1e-5)
```

---

## Requirements

### Python Packages
```
torch>=2.0.0
torchvision>=0.15.0
pandas>=1.5.0
numpy>=1.23.0
pillow>=9.0.0
scikit-learn>=1.2.0
tqdm>=4.65.0
matplotlib>=3.7.0
seaborn>=0.12.0
```

### Hardware
- **Training**: CPU works (slower), GPU recommended
  - Model 4b training: ~60 min on CPU, ~10 min on GPU
- **Inference**: CPU sufficient
  - Prediction: <5 min for typical test set

### Data
Download competition data from [Kaggle](https://www.kaggle.com/competitions/csiro-biomass-prediction/data) and place in `competition/` directory.

---

## Key Learnings

### 1. Target Normalization is Critical
- **Problem**: Large output scales (0-200g) cause training instability
- **Solution**: Normalize to mean=0, std=1 during training
- **Impact**: RÂ² improved from -1.25 â†’ +0.50+

### 2. Multimodal Train, Unimodal Test
- Best validation model (multimodal, RÂ²=+0.7537) cannot be submitted
- Need creative ways to transfer tabular knowledge to image-only models
- Auxiliary pretraining bridges this gap effectively

### 3. Auxiliary Pretraining Works
- Forcing model to predict tabular features from images teaches valuable patterns
- 88% state classification accuracy shows model learns geographic cues
- Significant improvement over simple image-only baseline (+0.6852 vs +0.6423)

### 4. Two-Phase Learning Rates
- Phase 1: Single LR (3e-4) for all parameters
- Phase 2: Differential LRs (1e-5 backbone, 3e-4 head)
- Prevents catastrophic forgetting of Phase 1 knowledge

### 5. Data Augmentation Helps (Slightly)
- ColorJitter: +0.0066 RÂ² improvement
- Geometric augmentations (flip, rotate): Standard practice
- Diminishing returns beyond basic augmentations

---

## Future Work

### Potential Improvements
1. **Larger backbones**: ResNet50/101, EfficientNet, Vision Transformers
2. **Ensemble methods**: Combine multiple Model 4b variations
3. **Advanced augmentation**: Mixup, CutMix, RandAugment
4. **Attention mechanisms**: Focus on relevant image regions
5. **Multi-task learning**: Joint prediction of tabular + biomass in Phase 2
6. **Pseudo-labeling**: Use multimodal model to generate soft labels
7. **Test-time augmentation**: Average predictions over augmented versions

### Alternative Approaches
- **Image captioning**: Generate text descriptions of tabular features
- **GAN-based**: Generate "tabular feature images" from photos
- **Contrastive learning**: Learn image-tabular alignment
- **Meta-learning**: Learn to adapt from multimodal to unimodal

---

## Acknowledgments

- **Competition**: [CSIRO Biomass Prediction](https://www.kaggle.com/competitions/csiro-biomass-prediction)
- **Framework**: PyTorch + torchvision
- **Pretrained models**: ImageNet (via torchvision)
- **Inspiration**: Knowledge distillation, auxiliary task learning, transfer learning literature

---

## License

MIT License - See LICENSE file for details

---

## Contact

For questions or collaboration:
- GitHub: [Create an issue](https://github.com/YOUR_USERNAME/csiro-biomass/issues)
- Competition Forum: [Kaggle Discussion](https://www.kaggle.com/competitions/csiro-biomass-prediction/discussion)

---

**Built with Claude Code** ðŸ¤–
