{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Baseline: Prove It Works First\n",
    "\n",
    "**Goal**: Build a minimal CNN that shows positive learning in just 5 epochs.\n",
    "\n",
    "## Problem Identified\n",
    "\n",
    "From feature exploration:\n",
    "- Simple linear regression on color: **R¬≤ = 0.20**\n",
    "- Complex CNN (25M params): **R¬≤ = -1.25** ‚ùå\n",
    "\n",
    "**Root causes:**\n",
    "1. ColorJitter destroying color signal (saturation=0.3 too aggressive)\n",
    "2. Model too complex (25M params, 285 training samples ‚Üí severe overfitting)\n",
    "3. Training too long without validation (40 epochs wasted)\n",
    "\n",
    "## This Notebook's Approach\n",
    "\n",
    "**Fixes applied:**\n",
    "- ‚ùå **NO ColorJitter** - preserve color information\n",
    "- üîß **ResNet18** instead of ResNet50 (11M ‚Üí simpler)\n",
    "- üîß **Simple FC head** - one layer (512 ‚Üí 256 ‚Üí 5)\n",
    "- ‚è±Ô∏è **5 epochs only** - fast validation (~5-7 minutes)\n",
    "- üìâ **Lower LR** - 1e-4 instead of 3e-4\n",
    "\n",
    "**Success criteria:**\n",
    "- Epoch 1: R¬≤ > -1.0 (better than before)\n",
    "- Epoch 3: R¬≤ > 0.0 (beat mean prediction)\n",
    "- Epoch 5: R¬≤ > 0.20 (beat linear regression)\n",
    "\n",
    "If this works ‚Üí Scale up to 20-30 epochs with early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(\"‚úì Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_enriched = pd.read_csv('competition/train_enriched.csv')\n",
    "train_enriched['Sampling_Date'] = pd.to_datetime(train_enriched['Sampling_Date'])\n",
    "train_enriched['full_image_path'] = train_enriched['image_path'].apply(lambda x: f'competition/{x}')\n",
    "\n",
    "# Target columns and weights\n",
    "target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "competition_weights = [0.1, 0.1, 0.1, 0.2, 0.5]\n",
    "\n",
    "# Train/val split\n",
    "train_data, val_data = train_test_split(train_enriched, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Total samples: {len(train_enriched)}\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"\\nTargets: {target_cols}\")\n",
    "print(f\"Competition weights: {competition_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset - NO ColorJitter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    \"\"\"Simple image dataset WITHOUT ColorJitter.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, image_size=224, augment=False):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        if augment:\n",
    "            print(\"Augmentation (NO ColorJitter):\")\n",
    "            print(\"  - RandomHorizontalFlip\")\n",
    "            print(\"  - RandomVerticalFlip\")\n",
    "            print(\"  - RandomRotation(10 degrees)\")\n",
    "            print(\"  - Standard normalization\")\n",
    "            \n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(10),\n",
    "                # NO ColorJitter - preserve color information!\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img = Image.open(row['full_image_path']).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        # Targets\n",
    "        targets = torch.tensor(\n",
    "            row[target_cols].values.astype('float32'),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        return {'image': img, 'targets': targets}\n",
    "\n",
    "# Create datasets\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = SimpleDataset(train_data, augment=True)\n",
    "val_dataset = SimpleDataset(val_data, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\n‚úì Datasets created\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Simple Model - ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"Simplified CNN: ResNet18 + single hidden layer.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_outputs=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ResNet18 backbone (lighter than ResNet50)\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        num_features = self.resnet.fc.in_features  # 512 for ResNet18\n",
    "        \n",
    "        # Simple FC head - just one hidden layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),  # Less dropout than before\n",
    "            nn.Linear(256, num_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Create model\n",
    "model = SimpleModel(num_outputs=5).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"‚úì Model architecture:\")\n",
    "print(f\"  Backbone: ResNet18 (pre-trained ImageNet)\")\n",
    "print(f\"  FC head: 512 ‚Üí 256 ‚Üí 5\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\n  Compare to previous: 25M+ params\")\n",
    "print(f\"  Reduction: {100 * (1 - trainable_params/25e6):.1f}% fewer parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Loss Function & Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitionLoss(nn.Module):\n",
    "    \"\"\"MSE loss weighted by competition metric.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]).to(device)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        mse = F.mse_loss(pred, target, reduction='none')\n",
    "        weighted_mse = (mse * self.weights).mean()\n",
    "        return weighted_mse\n",
    "\n",
    "criterion = CompetitionLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)  # Lower LR\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "print(\"‚úì Training setup:\")\n",
    "print(f\"  Loss: Competition-weighted MSE\")\n",
    "print(f\"  Optimizer: AdamW\")\n",
    "print(f\"  Learning rate: 1e-4 (lower than before)\")\n",
    "print(f\"  Weight decay: 1e-4\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau (patience=2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Loop - 5 Epochs Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images = batch['image'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    return train_loss / len(train_loader.dataset)\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    \"\"\"Validate and calculate R¬≤ scores.\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    # Calculate R¬≤ for each target\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    \n",
    "    r2_scores = []\n",
    "    competition_score = 0\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2 = r2_score(all_targets[:, i], all_preds[:, i])\n",
    "        r2_scores.append(r2)\n",
    "        competition_score += competition_weights[i] * r2\n",
    "    \n",
    "    return val_loss, competition_score, r2_scores\n",
    "\n",
    "print(\"‚úì Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_r2': [],\n",
    "    'epoch': []\n",
    "}\n",
    "\n",
    "best_r2 = -float('inf')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING SIMPLE BASELINE - 5 EPOCHS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nSuccess criteria:\")\n",
    "print(\"  Epoch 1: R¬≤ > -1.0 (better than previous -2.0)\")\n",
    "print(\"  Epoch 3: R¬≤ > 0.0 (beat mean prediction)\")\n",
    "print(\"  Epoch 5: R¬≤ > 0.20 (beat linear regression)\")\n",
    "print(\"\\nTraining...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_r2, r2_scores = validate(model, val_loader, criterion)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_r2'].append(val_r2)\n",
    "    history['epoch'].append(epoch + 1)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"  Val R¬≤:     {val_r2:+.4f}\")\n",
    "    \n",
    "    # Check milestones\n",
    "    if epoch == 0 and val_r2 > -1.0:\n",
    "        print(\"  ‚úì Milestone 1: Better than previous baseline!\")\n",
    "    if epoch == 2 and val_r2 > 0.0:\n",
    "        print(\"  ‚úì Milestone 2: Beat mean prediction!\")\n",
    "    if epoch == 4 and val_r2 > 0.20:\n",
    "        print(\"  ‚úì Milestone 3: Beat linear regression!\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_r2 > best_r2:\n",
    "        best_r2 = val_r2\n",
    "        torch.save(model.state_dict(), 'simple_baseline_best.pth')\n",
    "        print(f\"  üíæ New best R¬≤ = {best_r2:+.4f}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest validation R¬≤: {best_r2:+.4f}\")\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Simple linear regression: +0.2048\")\n",
    "print(f\"  Previous CNN baseline: -1.2527\")\n",
    "print(f\"  This simple CNN: {best_r2:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('simple_baseline_best.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Full evaluation\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        images = batch['image'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_targets = np.vstack(all_targets)\n",
    "\n",
    "# Calculate detailed metrics\n",
    "print(\"=\"*80)\n",
    "print(\"DETAILED RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "competition_score = 0\n",
    "for i, target in enumerate(target_cols):\n",
    "    r2 = r2_score(all_targets[:, i], all_preds[:, i])\n",
    "    mae = mean_absolute_error(all_targets[:, i], all_preds[:, i])\n",
    "    competition_score += competition_weights[i] * r2\n",
    "    \n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  R¬≤ = {r2:+.4f} (weight: {competition_weights[i]})\")\n",
    "    print(f\"  MAE = {mae:.2f}g\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Competition Score: {competition_score:+.4f}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax = axes[0]\n",
    "ax.plot(history['epoch'], history['train_loss'], 'o-', label='Train Loss', linewidth=2, markersize=8)\n",
    "ax.plot(history['epoch'], history['val_loss'], 's-', label='Val Loss', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Loss Curves (5 Epochs)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# R¬≤ curve\n",
    "ax = axes[1]\n",
    "ax.plot(history['epoch'], history['val_r2'], 'o-', color='green', linewidth=2, markersize=8, label='Val R¬≤')\n",
    "ax.axhline(y=0.0, color='gray', linestyle='--', linewidth=2, label='Baseline (predict mean)')\n",
    "ax.axhline(y=0.2048, color='orange', linestyle='--', linewidth=2, label='Linear regression')\n",
    "ax.axhline(y=-1.2527, color='red', linestyle='--', linewidth=2, label='Previous CNN')\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('R¬≤ Score', fontsize=12)\n",
    "ax.set_title('R¬≤ Progress (5 Epochs)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('simple_baseline_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Training curves saved to: simple_baseline_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Results Comparison:\")\n",
    "print(f\"\\n  Metric                  | Score\")\n",
    "print(f\"  \" + \"-\"*60)\n",
    "print(f\"  Linear regression       | {0.2048:+.4f}\")\n",
    "print(f\"  Previous CNN (40 epochs)| {-1.2527:+.4f}\")\n",
    "print(f\"  This simple CNN (5)     | {best_r2:+.4f}\")\n",
    "\n",
    "print(\"\\nüîß What Changed:\")\n",
    "print(\"  ‚ùå Removed ColorJitter (was destroying color signal)\")\n",
    "print(\"  üîß Simpler model: ResNet18 vs ResNet50\")\n",
    "print(\"  üîß Fewer parameters: ~11M vs 25M\")\n",
    "print(\"  üìâ Lower learning rate: 1e-4 vs 3e-4\")\n",
    "print(\"  ‚è±Ô∏è  Faster validation: 5 epochs vs 40\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if best_r2 > 0.20:\n",
    "    print(\"\\n‚úÖ SUCCESS! Simple CNN beats linear regression!\")\n",
    "    print(\"\\nRecommended next steps:\")\n",
    "    print(\"  1. Scale up to 20-30 epochs with early stopping\")\n",
    "    print(\"  2. Try slightly larger model (ResNet34?)\")\n",
    "    print(\"  3. Experiment with learning rate (1e-4 to 3e-4)\")\n",
    "    print(\"  4. Consider ensemble predictions\")\n",
    "    print(\"  5. Generate test set predictions\")\n",
    "    \n",
    "elif best_r2 > 0.0:\n",
    "    print(\"\\n‚ö†Ô∏è  PARTIAL SUCCESS: CNN beats mean prediction but not linear model\")\n",
    "    print(\"\\nRecommended next steps:\")\n",
    "    print(\"  1. Try more epochs (15-20)\")\n",
    "    print(\"  2. Experiment with learning rate\")\n",
    "    print(\"  3. Try ResNet34 (slightly larger)\")\n",
    "    print(\"  4. Add more aggressive geometric augmentation\")\n",
    "    print(\"  5. Consider feature concatenation (add color features to CNN)\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå STILL FAILING: R¬≤ < 0.0\")\n",
    "    print(\"\\nDeeper investigation needed:\")\n",
    "    print(\"  1. Check data loading: Are images loading correctly?\")\n",
    "    print(\"  2. Check loss function: Is it computing correctly?\")\n",
    "    print(\"  3. Check image-label alignment: IDs matching?\")\n",
    "    print(\"  4. Try even simpler model (linear layer on flattened images)\")\n",
    "    print(\"  5. Verify ImageNet normalization is appropriate\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì Simple baseline complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
